{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3a95f0a-c11e-43a4-8ac7-a50518df3d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from fastprogress.fastprogress import master_bar, progress_bar\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef45ffef-d3a0-48c5-bd8f-07916437d906",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=kernel_size//2)\n",
    "        self.bn1 = nn.BatchNorm1d(out_channels)\n",
    "        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size=kernel_size, stride=1, padding=kernel_size//2)\n",
    "        self.bn2 = nn.BatchNorm1d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.skip = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.skip = nn.Sequential(\n",
    "                nn.Conv1d(in_channels, out_channels, kernel_size=1, stride=stride),\n",
    "                nn.BatchNorm1d(out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.skip(x)\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "class AudioClassificationModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AudioClassificationModel, self).__init__()\n",
    "        self.embeddings = nn.ModuleList([nn.Embedding(1024, 6) for _ in range(9)])\n",
    "        \n",
    "        self.res_blocks = nn.Sequential(\n",
    "            *[ResidualBlock(54 if i == 0 else 120, 120, kernel_size=3, stride=2 if i == 0 else 1) for i in range(12)]\n",
    "        )\n",
    "        \n",
    "        # Placeholder for flattened size, to be dynamically determined\n",
    "        self.flattened_size = None\n",
    "        self.fc = None  # Placeholder for the fully connected layers, to be initialized once flattened size is known\n",
    "        \n",
    "    def forward(self, x):\n",
    "        embedded_rows = []\n",
    "        for i in range(9):\n",
    "            row = x[:, i, :]\n",
    "            embedded_row = self.embeddings[i](row)\n",
    "            embedded_row = embedded_row.transpose(1, 2)\n",
    "            embedded_rows.append(embedded_row)\n",
    "        \n",
    "        embedded_output = torch.stack(embedded_rows, dim=1)\n",
    "        embedded_output = embedded_output.reshape(x.shape[0], 54, -1)\n",
    "        \n",
    "        res_output = self.res_blocks(embedded_output)\n",
    "        res_output = res_output.view(res_output.size(0), -1)\n",
    "        \n",
    "        # Dynamically determine and initialize the fully connected layer if not already done\n",
    "        if self.fc is None:\n",
    "            self.flattened_size = res_output.shape[1]\n",
    "            self.fc = nn.Sequential(\n",
    "                nn.Linear(self.flattened_size, 512),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.5),\n",
    "                nn.Linear(512, 24)  # Output layer for 24 classes\n",
    "            ).to(res_output.device)  # Ensure the new layers are on the correct device\n",
    "        \n",
    "        output = self.fc(res_output)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13465be5-b360-4a0f-b2ae-e78135e8a408",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"danjacobellis/audio_har_descript_44kHz_frames_900\",split='train').with_format(\"torch\",device=\"cuda\")\n",
    "model = AudioClassificationModel().to(\"cuda\")\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b083db30-c219-4c63-be84-d5433297617d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Epoch 1: Train Loss: 3.3935<p>Epoch 2: Train Loss: 2.6504<p>Epoch 3: Train Loss: 2.2372<p>Epoch 4: Train Loss: 1.9332<p>Epoch 5: Train Loss: 1.6973<p>Epoch 6: Train Loss: 1.4859<p>Epoch 7: Train Loss: 1.2510<p>Epoch 8: Train Loss: 1.0459<p>Epoch 9: Train Loss: 0.8920<p>Epoch 10: Train Loss: 0.7184<p>Epoch 11: Train Loss: 0.6132<p>Epoch 12: Train Loss: 0.4909<p>Epoch 13: Train Loss: 0.4176<p>Epoch 14: Train Loss: 0.3844<p>Epoch 15: Train Loss: 0.3304<p>Epoch 16: Train Loss: 0.2857<p>Epoch 17: Train Loss: 0.2538<p>Epoch 18: Train Loss: 0.2326<p>Epoch 19: Train Loss: 0.2123<p>Epoch 20: Train Loss: 0.1787<p>Epoch 21: Train Loss: 0.1521<p>Epoch 22: Train Loss: 0.1567<p>Epoch 23: Train Loss: 0.1569<p>Epoch 24: Train Loss: 0.1550<p>Epoch 25: Train Loss: 0.1817<p>Epoch 26: Train Loss: 0.1767<p>Epoch 27: Train Loss: 0.1846<p>Epoch 28: Train Loss: 0.1806<p>Epoch 29: Train Loss: 0.1776<p>Epoch 30: Train Loss: 0.1550<p>Epoch 31: Train Loss: 0.1553<p>Epoch 32: Train Loss: 0.1555<p>Epoch 33: Train Loss: 0.1712<p>Epoch 34: Train Loss: 0.1755<p>Epoch 35: Train Loss: 0.1536<p>Epoch 36: Train Loss: 0.1533<p>Epoch 37: Train Loss: 0.1357<p>Epoch 38: Train Loss: 0.1321<p>Epoch 39: Train Loss: 0.1183<p>Epoch 40: Train Loss: 0.1328<p>Epoch 41: Train Loss: 0.1481<p>Epoch 42: Train Loss: 0.1476<p>Epoch 43: Train Loss: 0.1409<p>Epoch 44: Train Loss: 0.1069<p>Epoch 45: Train Loss: 0.1225<p>Epoch 46: Train Loss: 0.1052<p>Epoch 47: Train Loss: 0.1004<p>Epoch 48: Train Loss: 0.0946<p>Epoch 49: Train Loss: 0.1017<p>Epoch 50: Train Loss: 0.0911"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = 50\n",
    "mb = master_bar(range(1, epochs + 1))\n",
    "train_loss = []\n",
    "\n",
    "for epoch in mb:\n",
    "    dataloader = DataLoader(dataset, batch_size=64, shuffle=True, drop_last=True)\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs in progress_bar(dataloader, parent=mb):\n",
    "        codes = inputs['codes'].to(torch.int64)\n",
    "        targets = inputs['label']\n",
    "        one_hot_targets = F.one_hot(targets, num_classes=24).to(torch.float)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(codes)\n",
    "        loss = loss_function(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    epoch_loss = running_loss / len(dataloader)\n",
    "    train_loss.append(epoch_loss)\n",
    "\n",
    "    mb.write(f'Epoch {epoch}: Train Loss: {epoch_loss:.4f}')\n",
    "    \n",
    "    graphs = [[range(1, epoch + 1), train_loss]]\n",
    "    x_bounds = [1, epochs]\n",
    "    y_bounds = [min(train_loss) - 0.05, max(train_loss) + 0.05]\n",
    "    mb.update_graph(graphs, x_bounds, y_bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6654f6c8-2e7f-4e52-9c6f-441107573032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the training set: 100.00%\n",
      "F1 Score on the training set: 1.00\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "true_labels = []\n",
    "predicted_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs in dataloader:\n",
    "        codes = inputs['codes'].to(torch.int64)\n",
    "        targets = inputs['label']\n",
    "        true_labels.extend(targets.cpu().numpy())\n",
    "        outputs = model(codes)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        predicted_labels.extend(predicted.cpu().numpy())\n",
    "\n",
    "accuracy = np.mean(np.array(true_labels) == np.array(predicted_labels))\n",
    "print(f'Accuracy on the training set: {accuracy * 100:.2f}%')\n",
    "\n",
    "f1 = f1_score(true_labels, predicted_labels, average='weighted')\n",
    "print(f'F1 Score on the training set: {f1:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2005efc-fd24-4d02-aa14-a2664754251a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training excluding Participant 2\n",
      "Epoch 1/50, Participant 2: Loss = 3.4769\n",
      "Epoch 2/50, Participant 2: Loss = 2.8007\n",
      "Epoch 3/50, Participant 2: Loss = 2.3472\n",
      "Epoch 4/50, Participant 2: Loss = 2.0043\n",
      "Epoch 5/50, Participant 2: Loss = 1.6988\n",
      "Epoch 6/50, Participant 2: Loss = 1.4128\n",
      "Epoch 7/50, Participant 2: Loss = 1.1896\n",
      "Epoch 8/50, Participant 2: Loss = 0.9857\n",
      "Epoch 9/50, Participant 2: Loss = 0.8154\n",
      "Epoch 10/50, Participant 2: Loss = 0.6439\n",
      "Epoch 11/50, Participant 2: Loss = 0.5225\n",
      "Epoch 12/50, Participant 2: Loss = 0.4404\n",
      "Epoch 13/50, Participant 2: Loss = 0.3715\n",
      "Epoch 14/50, Participant 2: Loss = 0.3219\n",
      "Epoch 15/50, Participant 2: Loss = 0.2613\n",
      "Epoch 16/50, Participant 2: Loss = 0.2424\n",
      "Epoch 17/50, Participant 2: Loss = 0.2164\n",
      "Epoch 18/50, Participant 2: Loss = 0.2010\n",
      "Epoch 19/50, Participant 2: Loss = 0.2054\n",
      "Epoch 20/50, Participant 2: Loss = 0.1917\n",
      "Epoch 21/50, Participant 2: Loss = 0.1700\n",
      "Epoch 22/50, Participant 2: Loss = 0.1636\n",
      "Epoch 23/50, Participant 2: Loss = 0.1561\n",
      "Epoch 24/50, Participant 2: Loss = 0.1498\n",
      "Epoch 25/50, Participant 2: Loss = 0.1630\n",
      "Epoch 26/50, Participant 2: Loss = 0.1601\n",
      "Epoch 27/50, Participant 2: Loss = 0.1752\n",
      "Epoch 28/50, Participant 2: Loss = 0.1758\n",
      "Epoch 29/50, Participant 2: Loss = 0.1873\n",
      "Epoch 30/50, Participant 2: Loss = 0.2040\n",
      "Epoch 31/50, Participant 2: Loss = 0.2061\n",
      "Epoch 32/50, Participant 2: Loss = 0.1968\n",
      "Epoch 33/50, Participant 2: Loss = 0.2120\n",
      "Epoch 34/50, Participant 2: Loss = 0.1880\n",
      "Epoch 35/50, Participant 2: Loss = 0.1648\n",
      "Epoch 36/50, Participant 2: Loss = 0.1460\n",
      "Epoch 37/50, Participant 2: Loss = 0.1195\n",
      "Epoch 38/50, Participant 2: Loss = 0.1236\n",
      "Epoch 39/50, Participant 2: Loss = 0.1277\n",
      "Epoch 40/50, Participant 2: Loss = 0.1156\n",
      "Epoch 41/50, Participant 2: Loss = 0.0983\n",
      "Epoch 42/50, Participant 2: Loss = 0.0994\n",
      "Epoch 43/50, Participant 2: Loss = 0.1002\n",
      "Epoch 44/50, Participant 2: Loss = 0.0909\n",
      "Epoch 45/50, Participant 2: Loss = 0.0880\n",
      "Epoch 46/50, Participant 2: Loss = 0.0855\n",
      "Epoch 47/50, Participant 2: Loss = 0.0829\n",
      "Epoch 48/50, Participant 2: Loss = 0.0835\n",
      "Epoch 49/50, Participant 2: Loss = 0.0911\n",
      "Epoch 50/50, Participant 2: Loss = 0.0880\n",
      "LOPO Test Participant 2: Accuracy = 27.73%, F1 Score = 0.25\n",
      "Training excluding Participant 8\n",
      "Epoch 1/50, Participant 8: Loss = 3.4880\n",
      "Epoch 2/50, Participant 8: Loss = 2.7551\n",
      "Epoch 3/50, Participant 8: Loss = 2.3701\n",
      "Epoch 4/50, Participant 8: Loss = 2.0705\n",
      "Epoch 5/50, Participant 8: Loss = 1.7734\n",
      "Epoch 6/50, Participant 8: Loss = 1.5433\n",
      "Epoch 7/50, Participant 8: Loss = 1.3033\n",
      "Epoch 8/50, Participant 8: Loss = 1.0865\n",
      "Epoch 9/50, Participant 8: Loss = 0.9033\n",
      "Epoch 10/50, Participant 8: Loss = 0.7258\n",
      "Epoch 11/50, Participant 8: Loss = 0.5744\n",
      "Epoch 12/50, Participant 8: Loss = 0.4696\n",
      "Epoch 13/50, Participant 8: Loss = 0.3980\n",
      "Epoch 14/50, Participant 8: Loss = 0.3125\n",
      "Epoch 15/50, Participant 8: Loss = 0.2661\n",
      "Epoch 16/50, Participant 8: Loss = 0.2422\n",
      "Epoch 17/50, Participant 8: Loss = 0.2098\n",
      "Epoch 18/50, Participant 8: Loss = 0.1879\n",
      "Epoch 19/50, Participant 8: Loss = 0.1940\n",
      "Epoch 20/50, Participant 8: Loss = 0.1806\n",
      "Epoch 21/50, Participant 8: Loss = 0.1745\n",
      "Epoch 22/50, Participant 8: Loss = 0.1656\n",
      "Epoch 23/50, Participant 8: Loss = 0.1568\n",
      "Epoch 24/50, Participant 8: Loss = 0.1619\n",
      "Epoch 25/50, Participant 8: Loss = 0.1719\n",
      "Epoch 26/50, Participant 8: Loss = 0.1645\n",
      "Epoch 27/50, Participant 8: Loss = 0.1723\n",
      "Epoch 28/50, Participant 8: Loss = 0.1708\n",
      "Epoch 29/50, Participant 8: Loss = 0.1672\n",
      "Epoch 30/50, Participant 8: Loss = 0.1789\n",
      "Epoch 31/50, Participant 8: Loss = 0.1809\n",
      "Epoch 32/50, Participant 8: Loss = 0.1828\n",
      "Epoch 33/50, Participant 8: Loss = 0.1901\n",
      "Epoch 34/50, Participant 8: Loss = 0.1790\n",
      "Epoch 35/50, Participant 8: Loss = 0.1867\n",
      "Epoch 36/50, Participant 8: Loss = 0.1895\n",
      "Epoch 37/50, Participant 8: Loss = 0.1871\n",
      "Epoch 38/50, Participant 8: Loss = 0.1749\n",
      "Epoch 39/50, Participant 8: Loss = 0.1574\n",
      "Epoch 40/50, Participant 8: Loss = 0.1510\n",
      "Epoch 41/50, Participant 8: Loss = 0.1356\n",
      "Epoch 42/50, Participant 8: Loss = 0.1143\n",
      "Epoch 43/50, Participant 8: Loss = 0.0973\n",
      "Epoch 44/50, Participant 8: Loss = 0.0833\n",
      "Epoch 45/50, Participant 8: Loss = 0.0774\n",
      "Epoch 46/50, Participant 8: Loss = 0.0770\n",
      "Epoch 47/50, Participant 8: Loss = 0.0747\n",
      "Epoch 48/50, Participant 8: Loss = 0.0734\n",
      "Epoch 49/50, Participant 8: Loss = 0.0639\n",
      "Epoch 50/50, Participant 8: Loss = 0.0616\n",
      "LOPO Test Participant 8: Accuracy = 27.34%, F1 Score = 0.26\n",
      "Training excluding Participant 10\n",
      "Epoch 1/50, Participant 10: Loss = 3.5151\n",
      "Epoch 2/50, Participant 10: Loss = 2.7189\n",
      "Epoch 3/50, Participant 10: Loss = 2.2637\n",
      "Epoch 4/50, Participant 10: Loss = 1.9498\n",
      "Epoch 5/50, Participant 10: Loss = 1.6809\n",
      "Epoch 6/50, Participant 10: Loss = 1.4241\n",
      "Epoch 7/50, Participant 10: Loss = 1.2069\n",
      "Epoch 8/50, Participant 10: Loss = 1.0141\n",
      "Epoch 9/50, Participant 10: Loss = 0.8363\n",
      "Epoch 10/50, Participant 10: Loss = 0.6922\n",
      "Epoch 11/50, Participant 10: Loss = 0.5569\n",
      "Epoch 12/50, Participant 10: Loss = 0.4587\n",
      "Epoch 13/50, Participant 10: Loss = 0.3847\n",
      "Epoch 14/50, Participant 10: Loss = 0.3438\n",
      "Epoch 15/50, Participant 10: Loss = 0.3022\n",
      "Epoch 16/50, Participant 10: Loss = 0.2518\n",
      "Epoch 17/50, Participant 10: Loss = 0.2129\n",
      "Epoch 18/50, Participant 10: Loss = 0.1849\n",
      "Epoch 19/50, Participant 10: Loss = 0.1658\n",
      "Epoch 20/50, Participant 10: Loss = 0.1640\n",
      "Epoch 21/50, Participant 10: Loss = 0.1687\n",
      "Epoch 22/50, Participant 10: Loss = 0.1692\n",
      "Epoch 23/50, Participant 10: Loss = 0.1613\n",
      "Epoch 24/50, Participant 10: Loss = 0.1583\n",
      "Epoch 25/50, Participant 10: Loss = 0.1559\n",
      "Epoch 26/50, Participant 10: Loss = 0.1443\n",
      "Epoch 27/50, Participant 10: Loss = 0.1556\n",
      "Epoch 28/50, Participant 10: Loss = 0.1492\n",
      "Epoch 29/50, Participant 10: Loss = 0.1632\n",
      "Epoch 30/50, Participant 10: Loss = 0.1676\n",
      "Epoch 31/50, Participant 10: Loss = 0.1946\n",
      "Epoch 32/50, Participant 10: Loss = 0.1910\n",
      "Epoch 33/50, Participant 10: Loss = 0.2086\n",
      "Epoch 34/50, Participant 10: Loss = 0.1951\n",
      "Epoch 35/50, Participant 10: Loss = 0.1886\n",
      "Epoch 36/50, Participant 10: Loss = 0.1755\n",
      "Epoch 37/50, Participant 10: Loss = 0.1451\n",
      "Epoch 38/50, Participant 10: Loss = 0.1255\n",
      "Epoch 39/50, Participant 10: Loss = 0.1111\n",
      "Epoch 40/50, Participant 10: Loss = 0.1114\n",
      "Epoch 41/50, Participant 10: Loss = 0.0904\n",
      "Epoch 42/50, Participant 10: Loss = 0.0728\n",
      "Epoch 43/50, Participant 10: Loss = 0.0682\n",
      "Epoch 44/50, Participant 10: Loss = 0.0754\n",
      "Epoch 45/50, Participant 10: Loss = 0.0754\n",
      "Epoch 46/50, Participant 10: Loss = 0.0781\n",
      "Epoch 47/50, Participant 10: Loss = 0.0914\n",
      "Epoch 48/50, Participant 10: Loss = 0.0906\n",
      "Epoch 49/50, Participant 10: Loss = 0.0969\n",
      "Epoch 50/50, Participant 10: Loss = 0.1113\n",
      "LOPO Test Participant 10: Accuracy = 25.78%, F1 Score = 0.22\n",
      "Training excluding Participant 11\n",
      "Epoch 1/50, Participant 11: Loss = 3.4318\n",
      "Epoch 2/50, Participant 11: Loss = 2.7316\n",
      "Epoch 3/50, Participant 11: Loss = 2.3236\n",
      "Epoch 4/50, Participant 11: Loss = 2.0071\n",
      "Epoch 5/50, Participant 11: Loss = 1.7224\n",
      "Epoch 6/50, Participant 11: Loss = 1.4573\n",
      "Epoch 7/50, Participant 11: Loss = 1.2178\n",
      "Epoch 8/50, Participant 11: Loss = 1.0336\n",
      "Epoch 9/50, Participant 11: Loss = 0.8552\n",
      "Epoch 10/50, Participant 11: Loss = 0.6923\n",
      "Epoch 11/50, Participant 11: Loss = 0.5688\n",
      "Epoch 12/50, Participant 11: Loss = 0.4586\n",
      "Epoch 13/50, Participant 11: Loss = 0.3680\n",
      "Epoch 14/50, Participant 11: Loss = 0.3094\n",
      "Epoch 15/50, Participant 11: Loss = 0.2727\n",
      "Epoch 16/50, Participant 11: Loss = 0.2259\n",
      "Epoch 17/50, Participant 11: Loss = 0.2117\n",
      "Epoch 18/50, Participant 11: Loss = 0.1956\n",
      "Epoch 19/50, Participant 11: Loss = 0.1517\n",
      "Epoch 20/50, Participant 11: Loss = 0.1554\n",
      "Epoch 21/50, Participant 11: Loss = 0.1333\n",
      "Epoch 22/50, Participant 11: Loss = 0.1250\n",
      "Epoch 23/50, Participant 11: Loss = 0.1353\n",
      "Epoch 24/50, Participant 11: Loss = 0.1322\n",
      "Epoch 25/50, Participant 11: Loss = 0.1396\n",
      "Epoch 26/50, Participant 11: Loss = 0.1461\n",
      "Epoch 27/50, Participant 11: Loss = 0.1656\n",
      "Epoch 28/50, Participant 11: Loss = 0.1719\n",
      "Epoch 29/50, Participant 11: Loss = 0.1863\n",
      "Epoch 30/50, Participant 11: Loss = 0.2234\n",
      "Epoch 31/50, Participant 11: Loss = 0.2606\n",
      "Epoch 32/50, Participant 11: Loss = 0.2590\n",
      "Epoch 33/50, Participant 11: Loss = 0.2412\n",
      "Epoch 34/50, Participant 11: Loss = 0.2408\n",
      "Epoch 35/50, Participant 11: Loss = 0.2135\n",
      "Epoch 36/50, Participant 11: Loss = 0.1890\n",
      "Epoch 37/50, Participant 11: Loss = 0.1451\n",
      "Epoch 38/50, Participant 11: Loss = 0.1228\n",
      "Epoch 39/50, Participant 11: Loss = 0.1134\n",
      "Epoch 40/50, Participant 11: Loss = 0.1011\n",
      "Epoch 41/50, Participant 11: Loss = 0.0835\n",
      "Epoch 42/50, Participant 11: Loss = 0.0710\n",
      "Epoch 43/50, Participant 11: Loss = 0.0616\n",
      "Epoch 44/50, Participant 11: Loss = 0.0687\n",
      "Epoch 45/50, Participant 11: Loss = 0.0682\n",
      "Epoch 46/50, Participant 11: Loss = 0.0633\n",
      "Epoch 47/50, Participant 11: Loss = 0.0635\n",
      "Epoch 48/50, Participant 11: Loss = 0.0596\n",
      "Epoch 49/50, Participant 11: Loss = 0.0594\n",
      "Epoch 50/50, Participant 11: Loss = 0.0708\n",
      "LOPO Test Participant 11: Accuracy = 21.88%, F1 Score = 0.16\n",
      "Training excluding Participant 12\n",
      "Epoch 1/50, Participant 12: Loss = 3.4436\n",
      "Epoch 2/50, Participant 12: Loss = 2.7074\n",
      "Epoch 3/50, Participant 12: Loss = 2.2870\n",
      "Epoch 4/50, Participant 12: Loss = 1.9901\n",
      "Epoch 5/50, Participant 12: Loss = 1.7055\n",
      "Epoch 6/50, Participant 12: Loss = 1.4603\n",
      "Epoch 7/50, Participant 12: Loss = 1.2405\n",
      "Epoch 8/50, Participant 12: Loss = 0.9858\n",
      "Epoch 9/50, Participant 12: Loss = 0.8106\n",
      "Epoch 10/50, Participant 12: Loss = 0.6611\n",
      "Epoch 11/50, Participant 12: Loss = 0.5538\n",
      "Epoch 12/50, Participant 12: Loss = 0.4446\n",
      "Epoch 13/50, Participant 12: Loss = 0.3646\n",
      "Epoch 14/50, Participant 12: Loss = 0.3207\n",
      "Epoch 15/50, Participant 12: Loss = 0.2879\n",
      "Epoch 16/50, Participant 12: Loss = 0.2515\n",
      "Epoch 17/50, Participant 12: Loss = 0.2156\n",
      "Epoch 18/50, Participant 12: Loss = 0.1964\n",
      "Epoch 19/50, Participant 12: Loss = 0.1775\n",
      "Epoch 20/50, Participant 12: Loss = 0.1711\n",
      "Epoch 21/50, Participant 12: Loss = 0.1502\n",
      "Epoch 22/50, Participant 12: Loss = 0.1382\n",
      "Epoch 23/50, Participant 12: Loss = 0.1299\n",
      "Epoch 24/50, Participant 12: Loss = 0.1238\n",
      "Epoch 25/50, Participant 12: Loss = 0.1167\n",
      "Epoch 26/50, Participant 12: Loss = 0.1155\n",
      "Epoch 27/50, Participant 12: Loss = 0.1298\n",
      "Epoch 28/50, Participant 12: Loss = 0.1396\n",
      "Epoch 29/50, Participant 12: Loss = 0.1670\n",
      "Epoch 30/50, Participant 12: Loss = 0.1725\n",
      "Epoch 31/50, Participant 12: Loss = 0.1818\n",
      "Epoch 32/50, Participant 12: Loss = 0.2327\n",
      "Epoch 33/50, Participant 12: Loss = 0.2597\n",
      "Epoch 34/50, Participant 12: Loss = 0.2528\n",
      "Epoch 35/50, Participant 12: Loss = 0.2130\n",
      "Epoch 36/50, Participant 12: Loss = 0.1776\n",
      "Epoch 37/50, Participant 12: Loss = 0.1632\n",
      "Epoch 38/50, Participant 12: Loss = 0.1350\n",
      "Epoch 39/50, Participant 12: Loss = 0.1232\n",
      "Epoch 40/50, Participant 12: Loss = 0.1050\n",
      "Epoch 41/50, Participant 12: Loss = 0.0947\n",
      "Epoch 42/50, Participant 12: Loss = 0.0865\n",
      "Epoch 43/50, Participant 12: Loss = 0.0794\n",
      "Epoch 44/50, Participant 12: Loss = 0.0634\n",
      "Epoch 45/50, Participant 12: Loss = 0.0649\n",
      "Epoch 46/50, Participant 12: Loss = 0.0594\n",
      "Epoch 47/50, Participant 12: Loss = 0.0632\n",
      "Epoch 48/50, Participant 12: Loss = 0.0624\n",
      "Epoch 49/50, Participant 12: Loss = 0.0622\n",
      "Epoch 50/50, Participant 12: Loss = 0.0698\n",
      "LOPO Test Participant 12: Accuracy = 25.00%, F1 Score = 0.22\n",
      "Training excluding Participant 14\n",
      "Epoch 1/50, Participant 14: Loss = 3.5700\n",
      "Epoch 2/50, Participant 14: Loss = 2.7768\n",
      "Epoch 3/50, Participant 14: Loss = 2.3407\n",
      "Epoch 4/50, Participant 14: Loss = 2.0266\n",
      "Epoch 5/50, Participant 14: Loss = 1.7310\n",
      "Epoch 6/50, Participant 14: Loss = 1.4803\n",
      "Epoch 7/50, Participant 14: Loss = 1.2704\n",
      "Epoch 8/50, Participant 14: Loss = 1.0346\n",
      "Epoch 9/50, Participant 14: Loss = 0.8496\n",
      "Epoch 10/50, Participant 14: Loss = 0.7126\n",
      "Epoch 11/50, Participant 14: Loss = 0.5700\n",
      "Epoch 12/50, Participant 14: Loss = 0.4654\n",
      "Epoch 13/50, Participant 14: Loss = 0.3988\n",
      "Epoch 14/50, Participant 14: Loss = 0.3460\n",
      "Epoch 15/50, Participant 14: Loss = 0.2891\n",
      "Epoch 16/50, Participant 14: Loss = 0.2482\n",
      "Epoch 17/50, Participant 14: Loss = 0.2110\n",
      "Epoch 18/50, Participant 14: Loss = 0.1878\n",
      "Epoch 19/50, Participant 14: Loss = 0.1721\n",
      "Epoch 20/50, Participant 14: Loss = 0.1569\n",
      "Epoch 21/50, Participant 14: Loss = 0.1374\n",
      "Epoch 22/50, Participant 14: Loss = 0.1340\n",
      "Epoch 23/50, Participant 14: Loss = 0.1391\n",
      "Epoch 24/50, Participant 14: Loss = 0.1305\n",
      "Epoch 25/50, Participant 14: Loss = 0.1380\n",
      "Epoch 26/50, Participant 14: Loss = 0.1464\n",
      "Epoch 27/50, Participant 14: Loss = 0.1650\n",
      "Epoch 28/50, Participant 14: Loss = 0.1601\n",
      "Epoch 29/50, Participant 14: Loss = 0.1913\n",
      "Epoch 30/50, Participant 14: Loss = 0.2164\n",
      "Epoch 31/50, Participant 14: Loss = 0.2348\n",
      "Epoch 32/50, Participant 14: Loss = 0.2481\n",
      "Epoch 33/50, Participant 14: Loss = 0.2490\n",
      "Epoch 34/50, Participant 14: Loss = 0.2243\n",
      "Epoch 35/50, Participant 14: Loss = 0.2055\n",
      "Epoch 36/50, Participant 14: Loss = 0.1810\n",
      "Epoch 37/50, Participant 14: Loss = 0.1469\n",
      "Epoch 38/50, Participant 14: Loss = 0.1122\n",
      "Epoch 39/50, Participant 14: Loss = 0.0962\n",
      "Epoch 40/50, Participant 14: Loss = 0.0864\n",
      "Epoch 41/50, Participant 14: Loss = 0.0911\n",
      "Epoch 42/50, Participant 14: Loss = 0.0960\n",
      "Epoch 43/50, Participant 14: Loss = 0.0868\n",
      "Epoch 44/50, Participant 14: Loss = 0.0820\n",
      "Epoch 45/50, Participant 14: Loss = 0.0819\n",
      "Epoch 46/50, Participant 14: Loss = 0.0924\n",
      "Epoch 47/50, Participant 14: Loss = 0.0952\n",
      "Epoch 48/50, Participant 14: Loss = 0.0795\n",
      "Epoch 49/50, Participant 14: Loss = 0.0797\n",
      "Epoch 50/50, Participant 14: Loss = 0.0689\n",
      "LOPO Test Participant 14: Accuracy = 29.30%, F1 Score = 0.28\n",
      "Training excluding Participant 1\n",
      "Epoch 1/50, Participant 1: Loss = 3.4328\n",
      "Epoch 2/50, Participant 1: Loss = 2.6314\n",
      "Epoch 3/50, Participant 1: Loss = 2.2025\n",
      "Epoch 4/50, Participant 1: Loss = 1.9191\n",
      "Epoch 5/50, Participant 1: Loss = 1.6500\n",
      "Epoch 6/50, Participant 1: Loss = 1.3784\n",
      "Epoch 7/50, Participant 1: Loss = 1.1389\n",
      "Epoch 8/50, Participant 1: Loss = 0.9950\n",
      "Epoch 9/50, Participant 1: Loss = 0.8075\n",
      "Epoch 10/50, Participant 1: Loss = 0.6735\n",
      "Epoch 11/50, Participant 1: Loss = 0.5249\n",
      "Epoch 12/50, Participant 1: Loss = 0.4173\n",
      "Epoch 13/50, Participant 1: Loss = 0.3347\n",
      "Epoch 14/50, Participant 1: Loss = 0.2913\n",
      "Epoch 15/50, Participant 1: Loss = 0.2654\n",
      "Epoch 16/50, Participant 1: Loss = 0.2308\n",
      "Epoch 17/50, Participant 1: Loss = 0.2078\n",
      "Epoch 18/50, Participant 1: Loss = 0.2020\n",
      "Epoch 19/50, Participant 1: Loss = 0.1807\n",
      "Epoch 20/50, Participant 1: Loss = 0.1642\n",
      "Epoch 21/50, Participant 1: Loss = 0.1602\n",
      "Epoch 22/50, Participant 1: Loss = 0.1417\n",
      "Epoch 23/50, Participant 1: Loss = 0.1433\n",
      "Epoch 24/50, Participant 1: Loss = 0.1310\n",
      "Epoch 25/50, Participant 1: Loss = 0.1357\n",
      "Epoch 26/50, Participant 1: Loss = 0.1435\n",
      "Epoch 27/50, Participant 1: Loss = 0.1602\n",
      "Epoch 28/50, Participant 1: Loss = 0.1617\n",
      "Epoch 29/50, Participant 1: Loss = 0.1782\n",
      "Epoch 30/50, Participant 1: Loss = 0.1915\n",
      "Epoch 31/50, Participant 1: Loss = 0.1850\n"
     ]
    }
   ],
   "source": [
    "participants = set(dataset['participant'].unique())\n",
    "\n",
    "results = []\n",
    "\n",
    "for test_participant in participants:\n",
    "    print(f\"Training excluding Participant {test_participant}\")\n",
    "    train_indices = [i for i, p in enumerate(dataset['participant']) if p != test_participant]\n",
    "    test_indices = [i for i, p in enumerate(dataset['participant']) if p == test_participant]\n",
    "    train_data = dataset.select(train_indices)\n",
    "    test_data = dataset.select(test_indices)\n",
    "    model = AudioClassificationModel().to(\"cuda\")\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=0.001)\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        train_dataloader = DataLoader(train_data, batch_size=64, shuffle=True, drop_last=True)\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for inputs in train_dataloader:\n",
    "            codes = inputs['codes'].to(torch.int64)\n",
    "            targets = inputs['label']\n",
    "            one_hot_targets = F.one_hot(targets, num_classes=24).to(torch.float)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(codes)\n",
    "            loss = loss_function(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        epoch_loss = running_loss / len(train_dataloader)\n",
    "        print(f'Epoch {epoch}/{epochs}, Participant {test_participant}: Loss = {epoch_loss:.4f}')\n",
    "    \n",
    "    test_dataloader = DataLoader(test_data, batch_size=64, shuffle=False, drop_last=True)\n",
    "    model.eval()\n",
    "    true_labels = []\n",
    "    predicted_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs in test_dataloader:\n",
    "            codes = inputs['codes'].to(torch.int64)\n",
    "            targets = inputs['label']\n",
    "            true_labels.extend(targets.cpu().numpy())\n",
    "            outputs = model(codes)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            predicted_labels.extend(predicted.cpu().numpy())\n",
    "\n",
    "    accuracy = np.mean(np.array(true_labels) == np.array(predicted_labels))\n",
    "    f1 = f1_score(true_labels, predicted_labels, average='weighted')\n",
    "\n",
    "    print(f'LOPO Test Participant {test_participant}: Accuracy = {accuracy * 100:.2f}%, F1 Score = {f1:.2f}')\n",
    "    results.append((test_participant, accuracy, f1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
