{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3a95f0a-c11e-43a4-8ac7-a50518df3d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from fastprogress.fastprogress import master_bar, progress_bar\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef45ffef-d3a0-48c5-bd8f-07916437d906",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SequenceModel, self).__init__()\n",
    "        self.num_positions = 9\n",
    "        self.num_embeddings = 1024\n",
    "        self.embedding_dim = 6\n",
    "        \n",
    "        self.embeddings = nn.ModuleList([\n",
    "            nn.Embedding(num_embeddings=self.num_embeddings, embedding_dim=self.embedding_dim) \n",
    "            for _ in range(self.num_positions)\n",
    "        ])\n",
    "        \n",
    "        self.conv1 = nn.Conv1d(in_channels=54,  out_channels=72,  kernel_size=3, stride=3)\n",
    "        self.conv2 = nn.Conv1d(in_channels=72,  out_channels=120, kernel_size=3, stride=3)\n",
    "        \n",
    "        self.fc1 = nn.Linear(120, 120)\n",
    "        self.fc2 = nn.Linear(120, 24)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        embeddings = [self.embeddings[i](x[:, :, i]) for i in range(self.num_positions)]\n",
    "        embeddings = torch.stack(embeddings, dim=3)\n",
    "        reshaped = embeddings.view(batch_size, 54, -1)\n",
    "        x = F.relu(self.conv1(reshaped))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = x.view(batch_size, -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13465be5-b360-4a0f-b2ae-e78135e8a408",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"danjacobellis/audio_har_descript_44kHz_frames\",split='train').with_format(\"torch\",device=\"cuda\")\n",
    "model = SequenceModel().to(\"cuda\")\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b083db30-c219-4c63-be84-d5433297617d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Epoch 1: Train Loss: 2.9977<p>Epoch 2: Train Loss: 2.6648<p>Epoch 3: Train Loss: 2.4723<p>Epoch 4: Train Loss: 2.3175<p>Epoch 5: Train Loss: 2.1481<p>Epoch 6: Train Loss: 1.9803<p>Epoch 7: Train Loss: 1.8072<p>Epoch 8: Train Loss: 1.6289<p>Epoch 9: Train Loss: 1.4534<p>Epoch 10: Train Loss: 1.2785<p>Epoch 11: Train Loss: 1.1061<p>Epoch 12: Train Loss: 0.9372<p>Epoch 13: Train Loss: 0.7767<p>Epoch 14: Train Loss: 0.6286<p>Epoch 15: Train Loss: 0.4970<p>Epoch 16: Train Loss: 0.3854<p>Epoch 17: Train Loss: 0.2827<p>Epoch 18: Train Loss: 0.2036<p>Epoch 19: Train Loss: 0.1342<p>Epoch 20: Train Loss: 0.0849<p>Epoch 21: Train Loss: 0.0529<p>Epoch 22: Train Loss: 0.0339<p>Epoch 23: Train Loss: 0.0227<p>Epoch 24: Train Loss: 0.0165<p>Epoch 25: Train Loss: 0.0124<p>Epoch 26: Train Loss: 0.0101<p>Epoch 27: Train Loss: 0.0086<p>Epoch 28: Train Loss: 0.0073<p>Epoch 29: Train Loss: 0.0062<p>Epoch 30: Train Loss: 0.0055<p>Epoch 31: Train Loss: 0.0048<p>Epoch 32: Train Loss: 0.0042<p>Epoch 33: Train Loss: 0.0037<p>Epoch 34: Train Loss: 0.0033<p>Epoch 35: Train Loss: 0.0029<p>Epoch 36: Train Loss: 0.0026<p>Epoch 37: Train Loss: 0.0024<p>Epoch 38: Train Loss: 0.0021<p>Epoch 39: Train Loss: 0.0019<p>Epoch 40: Train Loss: 0.0017<p>Epoch 41: Train Loss: 0.0015<p>Epoch 42: Train Loss: 0.0014<p>Epoch 43: Train Loss: 0.0013<p>Epoch 44: Train Loss: 0.0011<p>Epoch 45: Train Loss: 0.0010<p>Epoch 46: Train Loss: 0.0009<p>Epoch 47: Train Loss: 0.0009<p>Epoch 48: Train Loss: 0.0008<p>Epoch 49: Train Loss: 0.0007<p>Epoch 50: Train Loss: 0.0006<p>Epoch 51: Train Loss: 0.0006<p>Epoch 52: Train Loss: 0.0005<p>Epoch 53: Train Loss: 0.0005<p>Epoch 54: Train Loss: 0.0004<p>Epoch 55: Train Loss: 0.0004<p>Epoch 56: Train Loss: 0.0004<p>Epoch 57: Train Loss: 0.0003<p>Epoch 58: Train Loss: 0.0003<p>Epoch 59: Train Loss: 0.0003<p>Epoch 60: Train Loss: 0.0003<p>Epoch 61: Train Loss: 0.0002<p>Epoch 62: Train Loss: 0.0002<p>Epoch 63: Train Loss: 0.0002<p>Epoch 64: Train Loss: 0.0002<p>Epoch 65: Train Loss: 0.0002<p>Epoch 66: Train Loss: 0.0002<p>Epoch 67: Train Loss: 0.0001<p>Epoch 68: Train Loss: 0.0001<p>Epoch 69: Train Loss: 0.0001<p>Epoch 70: Train Loss: 0.0001<p>Epoch 71: Train Loss: 0.0001<p>Epoch 72: Train Loss: 0.0001<p>Epoch 73: Train Loss: 0.0001<p>Epoch 74: Train Loss: 0.0001<p>Epoch 75: Train Loss: 0.0001<p>Epoch 76: Train Loss: 0.0001<p>Epoch 77: Train Loss: 0.0001<p>Epoch 78: Train Loss: 0.0001<p>Epoch 79: Train Loss: 0.0000<p>Epoch 80: Train Loss: 0.0000<p>Epoch 81: Train Loss: 0.0000<p>Epoch 82: Train Loss: 0.0000<p>Epoch 83: Train Loss: 0.0000<p>Epoch 84: Train Loss: 0.0000<p>Epoch 85: Train Loss: 0.0000<p>Epoch 86: Train Loss: 0.0000<p>Epoch 87: Train Loss: 0.0000<p>Epoch 88: Train Loss: 0.0000<p>Epoch 89: Train Loss: 0.0000<p>Epoch 90: Train Loss: 0.0000<p>Epoch 91: Train Loss: 0.0000<p>Epoch 92: Train Loss: 0.0000<p>Epoch 93: Train Loss: 0.0000<p>Epoch 94: Train Loss: 0.0000<p>Epoch 95: Train Loss: 0.0000<p>Epoch 96: Train Loss: 0.0000<p>Epoch 97: Train Loss: 0.0000<p>Epoch 98: Train Loss: 0.0000<p>Epoch 99: Train Loss: 0.0000<p>Epoch 100: Train Loss: 0.0000<p>Epoch 101: Train Loss: 0.0000<p>Epoch 102: Train Loss: 0.0000<p>Epoch 103: Train Loss: 0.0000<p>Epoch 104: Train Loss: 0.0000<p>Epoch 105: Train Loss: 0.0000<p>Epoch 106: Train Loss: 0.0000<p>Epoch 107: Train Loss: 0.0000<p>Epoch 108: Train Loss: 0.0000<p>Epoch 109: Train Loss: 0.0000<p>Epoch 110: Train Loss: 0.0000<p>Epoch 111: Train Loss: 0.0000<p>Epoch 112: Train Loss: 0.0000<p>Epoch 113: Train Loss: 0.0000<p>Epoch 114: Train Loss: 0.0000<p>Epoch 115: Train Loss: 0.0000<p>Epoch 116: Train Loss: 0.0000<p>Epoch 117: Train Loss: 0.0000<p>Epoch 118: Train Loss: 0.0000<p>Epoch 119: Train Loss: 0.0000<p>Epoch 120: Train Loss: 0.0000<p>Epoch 121: Train Loss: 0.0000<p>Epoch 122: Train Loss: 0.0000<p>Epoch 123: Train Loss: 0.0000<p>Epoch 124: Train Loss: 0.0000<p>Epoch 125: Train Loss: 0.0000<p>Epoch 126: Train Loss: 0.0000<p>Epoch 127: Train Loss: 0.0000<p>Epoch 128: Train Loss: 0.0000<p>Epoch 129: Train Loss: 0.0000<p>Epoch 130: Train Loss: 0.0000<p>Epoch 131: Train Loss: 0.0000<p>Epoch 132: Train Loss: 0.0000<p>Epoch 133: Train Loss: 0.0000<p>Epoch 134: Train Loss: 0.0000<p>Epoch 135: Train Loss: 0.0000<p>Epoch 136: Train Loss: 0.0000<p>Epoch 137: Train Loss: 0.0000<p>Epoch 138: Train Loss: 0.0000<p>Epoch 139: Train Loss: 0.0000<p>Epoch 140: Train Loss: 0.0000<p>Epoch 141: Train Loss: 0.0000<p>Epoch 142: Train Loss: 0.0000<p>Epoch 143: Train Loss: 0.0000<p>Epoch 144: Train Loss: 0.0000<p>Epoch 145: Train Loss: 0.0000<p>Epoch 146: Train Loss: 0.0000<p>Epoch 147: Train Loss: 0.0000<p>Epoch 148: Train Loss: 0.0000<p>Epoch 149: Train Loss: 0.0000<p>Epoch 150: Train Loss: 0.0000<p>Epoch 151: Train Loss: 0.0000<p>Epoch 152: Train Loss: 0.0000<p>Epoch 153: Train Loss: 0.0000<p>Epoch 154: Train Loss: 0.0000<p>Epoch 155: Train Loss: 0.0000<p>Epoch 156: Train Loss: 0.0000<p>Epoch 157: Train Loss: 0.0000<p>Epoch 158: Train Loss: 0.0000<p>Epoch 159: Train Loss: 0.0000<p>Epoch 160: Train Loss: 0.0000<p>Epoch 161: Train Loss: 0.0000<p>Epoch 162: Train Loss: 0.0000<p>Epoch 163: Train Loss: 0.0000<p>Epoch 164: Train Loss: 1.7137<p>Epoch 165: Train Loss: 0.3053<p>Epoch 166: Train Loss: 0.0461<p>Epoch 167: Train Loss: 0.0079<p>Epoch 168: Train Loss: 0.0029<p>Epoch 169: Train Loss: 0.0019<p>Epoch 170: Train Loss: 0.0016<p>Epoch 171: Train Loss: 0.0014<p>Epoch 172: Train Loss: 0.0012<p>Epoch 173: Train Loss: 0.0011<p>Epoch 174: Train Loss: 0.0010<p>Epoch 175: Train Loss: 0.0009<p>Epoch 176: Train Loss: 0.0009<p>Epoch 177: Train Loss: 0.0008<p>Epoch 178: Train Loss: 0.0008<p>Epoch 179: Train Loss: 0.0007<p>Epoch 180: Train Loss: 0.0007<p>Epoch 181: Train Loss: 0.0006<p>Epoch 182: Train Loss: 0.0006<p>Epoch 183: Train Loss: 0.0005<p>Epoch 184: Train Loss: 0.0005<p>Epoch 185: Train Loss: 0.0005<p>Epoch 186: Train Loss: 0.0005<p>Epoch 187: Train Loss: 0.0004<p>Epoch 188: Train Loss: 0.0004<p>Epoch 189: Train Loss: 0.0004<p>Epoch 190: Train Loss: 0.0004<p>Epoch 191: Train Loss: 0.0003<p>Epoch 192: Train Loss: 0.0003<p>Epoch 193: Train Loss: 0.0003<p>Epoch 194: Train Loss: 0.0003<p>Epoch 195: Train Loss: 0.0003<p>Epoch 196: Train Loss: 0.0003<p>Epoch 197: Train Loss: 0.0002<p>Epoch 198: Train Loss: 0.0002<p>Epoch 199: Train Loss: 0.0002<p>Epoch 200: Train Loss: 0.0002<p>Epoch 201: Train Loss: 0.0002<p>Epoch 202: Train Loss: 0.0002<p>Epoch 203: Train Loss: 0.0002<p>Epoch 204: Train Loss: 0.0002<p>Epoch 205: Train Loss: 0.0001<p>Epoch 206: Train Loss: 0.0001<p>Epoch 207: Train Loss: 0.0001<p>Epoch 208: Train Loss: 0.0001<p>Epoch 209: Train Loss: 0.0001<p>Epoch 210: Train Loss: 0.0001<p>Epoch 211: Train Loss: 0.0001<p>Epoch 212: Train Loss: 0.0001<p>Epoch 213: Train Loss: 0.0001<p>Epoch 214: Train Loss: 0.0001<p>Epoch 215: Train Loss: 0.0001<p>Epoch 216: Train Loss: 0.0001<p>Epoch 217: Train Loss: 0.0001<p>Epoch 218: Train Loss: 0.0001<p>Epoch 219: Train Loss: 0.0001<p>Epoch 220: Train Loss: 0.0001<p>Epoch 221: Train Loss: 0.0001<p>Epoch 222: Train Loss: 0.0001<p>Epoch 223: Train Loss: 0.0000<p>Epoch 224: Train Loss: 0.0000<p>Epoch 225: Train Loss: 0.0000<p>Epoch 226: Train Loss: 0.0000<p>Epoch 227: Train Loss: 0.0000<p>Epoch 228: Train Loss: 0.0000<p>Epoch 229: Train Loss: 0.0000<p>Epoch 230: Train Loss: 0.0000<p>Epoch 231: Train Loss: 0.0000<p>Epoch 232: Train Loss: 0.0000<p>Epoch 233: Train Loss: 0.0000<p>Epoch 234: Train Loss: 0.0000<p>Epoch 235: Train Loss: 0.0000<p>Epoch 236: Train Loss: 0.0000<p>Epoch 237: Train Loss: 0.0000<p>Epoch 238: Train Loss: 0.0000<p>Epoch 239: Train Loss: 0.0000<p>Epoch 240: Train Loss: 0.0000<p>Epoch 241: Train Loss: 0.0000<p>Epoch 242: Train Loss: 0.0000<p>Epoch 243: Train Loss: 0.0000<p>Epoch 244: Train Loss: 0.0000<p>Epoch 245: Train Loss: 0.0000<p>Epoch 246: Train Loss: 0.0000<p>Epoch 247: Train Loss: 0.0000<p>Epoch 248: Train Loss: 0.0000<p>Epoch 249: Train Loss: 0.0000<p>Epoch 250: Train Loss: 0.0000<p>Epoch 251: Train Loss: 0.0000<p>Epoch 252: Train Loss: 0.0000<p>Epoch 253: Train Loss: 0.0000<p>Epoch 254: Train Loss: 0.0000<p>Epoch 255: Train Loss: 0.0000<p>Epoch 256: Train Loss: 0.0000<p>Epoch 257: Train Loss: 0.0000<p>Epoch 258: Train Loss: 0.0000<p>Epoch 259: Train Loss: 0.0000<p>Epoch 260: Train Loss: 0.0000<p>Epoch 261: Train Loss: 0.0000<p>Epoch 262: Train Loss: 0.0000<p>Epoch 263: Train Loss: 0.0000<p>Epoch 264: Train Loss: 0.0000<p>Epoch 265: Train Loss: 0.0000<p>Epoch 266: Train Loss: 0.0000<p>Epoch 267: Train Loss: 0.0000<p>Epoch 268: Train Loss: 0.0000<p>Epoch 269: Train Loss: 0.0000<p>Epoch 270: Train Loss: 0.0000<p>Epoch 271: Train Loss: 0.0000<p>Epoch 272: Train Loss: 0.0000<p>Epoch 273: Train Loss: 0.0000<p>Epoch 274: Train Loss: 0.0000<p>Epoch 275: Train Loss: 0.0000<p>Epoch 276: Train Loss: 0.0000<p>Epoch 277: Train Loss: 0.0000<p>Epoch 278: Train Loss: 0.0000<p>Epoch 279: Train Loss: 0.0000<p>Epoch 280: Train Loss: 0.0000<p>Epoch 281: Train Loss: 0.0000<p>Epoch 282: Train Loss: 0.0000<p>Epoch 283: Train Loss: 0.0000<p>Epoch 284: Train Loss: 0.0000<p>Epoch 285: Train Loss: 0.0000<p>Epoch 286: Train Loss: 0.0000<p>Epoch 287: Train Loss: 0.0000<p>Epoch 288: Train Loss: 0.0000<p>Epoch 289: Train Loss: 0.0000<p>Epoch 290: Train Loss: 0.0000<p>Epoch 291: Train Loss: 0.0000<p>Epoch 292: Train Loss: 0.0000<p>Epoch 293: Train Loss: 0.0000<p>Epoch 294: Train Loss: 0.0000<p>Epoch 295: Train Loss: 0.0000<p>Epoch 296: Train Loss: 0.0000<p>Epoch 297: Train Loss: 0.0000<p>Epoch 298: Train Loss: 0.0000<p>Epoch 299: Train Loss: 0.0000<p>Epoch 300: Train Loss: 0.0000<p>Epoch 301: Train Loss: 0.0000<p>Epoch 302: Train Loss: 0.0000<p>Epoch 303: Train Loss: 0.0000<p>Epoch 304: Train Loss: 0.0000<p>Epoch 305: Train Loss: 0.0000<p>Epoch 306: Train Loss: 0.0000<p>Epoch 307: Train Loss: 0.0000<p>Epoch 308: Train Loss: 0.0000<p>Epoch 309: Train Loss: 0.0000<p>Epoch 310: Train Loss: 0.0000<p>Epoch 311: Train Loss: 0.0000<p>Epoch 312: Train Loss: 0.0000<p>Epoch 313: Train Loss: 0.0000<p>Epoch 314: Train Loss: 0.0000<p>Epoch 315: Train Loss: 0.0000<p>Epoch 316: Train Loss: 0.1321<p>Epoch 317: Train Loss: 1.3585<p>Epoch 318: Train Loss: 0.1719<p>Epoch 319: Train Loss: 0.0245<p>Epoch 320: Train Loss: 0.0034<p>Epoch 321: Train Loss: 0.0014<p>Epoch 322: Train Loss: 0.0011<p>Epoch 323: Train Loss: 0.0009<p>Epoch 324: Train Loss: 0.0008<p>Epoch 325: Train Loss: 0.0008<p>Epoch 326: Train Loss: 0.0007<p>Epoch 327: Train Loss: 0.0006<p>Epoch 328: Train Loss: 0.0006<p>Epoch 329: Train Loss: 0.0006<p>Epoch 330: Train Loss: 0.0005<p>Epoch 331: Train Loss: 0.0005<p>Epoch 332: Train Loss: 0.0005<p>Epoch 333: Train Loss: 0.0004<p>Epoch 334: Train Loss: 0.0004<p>Epoch 335: Train Loss: 0.0004<p>Epoch 336: Train Loss: 0.0004<p>Epoch 337: Train Loss: 0.0004<p>Epoch 338: Train Loss: 0.0003<p>Epoch 339: Train Loss: 0.0003<p>Epoch 340: Train Loss: 0.0003<p>Epoch 341: Train Loss: 0.0003<p>Epoch 342: Train Loss: 0.0003<p>Epoch 343: Train Loss: 0.0003<p>Epoch 344: Train Loss: 0.0003<p>Epoch 345: Train Loss: 0.0002<p>Epoch 346: Train Loss: 0.0002<p>Epoch 347: Train Loss: 0.0002<p>Epoch 348: Train Loss: 0.0002<p>Epoch 349: Train Loss: 0.0002<p>Epoch 350: Train Loss: 0.0002<p>Epoch 351: Train Loss: 0.0002<p>Epoch 352: Train Loss: 0.0002<p>Epoch 353: Train Loss: 0.0002<p>Epoch 354: Train Loss: 0.0002<p>Epoch 355: Train Loss: 0.0001<p>Epoch 356: Train Loss: 0.0001<p>Epoch 357: Train Loss: 0.0001<p>Epoch 358: Train Loss: 0.0001<p>Epoch 359: Train Loss: 0.0001<p>Epoch 360: Train Loss: 0.0001<p>Epoch 361: Train Loss: 0.0001<p>Epoch 362: Train Loss: 0.0001<p>Epoch 363: Train Loss: 0.0001<p>Epoch 364: Train Loss: 0.0001<p>Epoch 365: Train Loss: 0.0001<p>Epoch 366: Train Loss: 0.0001<p>Epoch 367: Train Loss: 0.0001<p>Epoch 368: Train Loss: 0.0001<p>Epoch 369: Train Loss: 0.0001<p>Epoch 370: Train Loss: 0.0001<p>Epoch 371: Train Loss: 0.0001<p>Epoch 372: Train Loss: 0.0001<p>Epoch 373: Train Loss: 0.0001<p>Epoch 374: Train Loss: 0.0001<p>Epoch 375: Train Loss: 0.0001<p>Epoch 376: Train Loss: 0.0000<p>Epoch 377: Train Loss: 0.0000<p>Epoch 378: Train Loss: 0.0000<p>Epoch 379: Train Loss: 0.0000<p>Epoch 380: Train Loss: 0.0000<p>Epoch 381: Train Loss: 0.0000<p>Epoch 382: Train Loss: 0.0000<p>Epoch 383: Train Loss: 0.0000<p>Epoch 384: Train Loss: 0.0000<p>Epoch 385: Train Loss: 0.0000<p>Epoch 386: Train Loss: 0.0000<p>Epoch 387: Train Loss: 0.0000<p>Epoch 388: Train Loss: 0.0000<p>Epoch 389: Train Loss: 0.0000<p>Epoch 390: Train Loss: 0.0000<p>Epoch 391: Train Loss: 0.0000<p>Epoch 392: Train Loss: 0.0000<p>Epoch 393: Train Loss: 0.0000<p>Epoch 394: Train Loss: 0.0000<p>Epoch 395: Train Loss: 0.0000<p>Epoch 396: Train Loss: 0.0000<p>Epoch 397: Train Loss: 0.0000<p>Epoch 398: Train Loss: 0.0000<p>Epoch 399: Train Loss: 0.0000<p>Epoch 400: Train Loss: 0.0000"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = 400\n",
    "mb = master_bar(range(1, epochs + 1))\n",
    "train_loss = []\n",
    "\n",
    "for epoch in mb:\n",
    "    dataloader = DataLoader(dataset, batch_size=64, shuffle=True, drop_last=True)\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs in progress_bar(dataloader, parent=mb):\n",
    "        codes = inputs['codes'].to(torch.int64)\n",
    "        targets = inputs['label']\n",
    "        one_hot_targets = F.one_hot(targets, num_classes=24).to(torch.float)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(codes)\n",
    "        loss = loss_function(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    epoch_loss = running_loss / len(dataloader)\n",
    "    train_loss.append(epoch_loss)\n",
    "\n",
    "    mb.write(f'Epoch {epoch}: Train Loss: {epoch_loss:.4f}')\n",
    "    \n",
    "    graphs = [[range(1, epoch + 1), train_loss]]\n",
    "    x_bounds = [1, epochs]\n",
    "    y_bounds = [min(train_loss) - 0.05, max(train_loss) + 0.05]\n",
    "    mb.update_graph(graphs, x_bounds, y_bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6654f6c8-2e7f-4e52-9c6f-441107573032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the training set: 100.00%\n",
      "F1 Score on the training set: 1.00\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "true_labels = []\n",
    "predicted_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs in dataloader:\n",
    "        codes = inputs['codes'].to(torch.int64)\n",
    "        targets = inputs['label']\n",
    "        true_labels.extend(targets.cpu().numpy())\n",
    "        outputs = model(codes)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        predicted_labels.extend(predicted.cpu().numpy())\n",
    "\n",
    "accuracy = np.mean(np.array(true_labels) == np.array(predicted_labels))\n",
    "print(f'Accuracy on the training set: {accuracy * 100:.2f}%')\n",
    "\n",
    "f1 = f1_score(true_labels, predicted_labels, average='weighted')\n",
    "print(f'F1 Score on the training set: {f1:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2005efc-fd24-4d02-aa14-a2664754251a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training excluding Participant 2\n",
      "Epoch 1/400, Participant 2: Loss = 2.9752\n",
      "Epoch 2/400, Participant 2: Loss = 2.6113\n",
      "Epoch 3/400, Participant 2: Loss = 2.4287\n",
      "Epoch 4/400, Participant 2: Loss = 2.2758\n",
      "Epoch 5/400, Participant 2: Loss = 2.1191\n",
      "Epoch 6/400, Participant 2: Loss = 1.9613\n",
      "Epoch 7/400, Participant 2: Loss = 1.7951\n",
      "Epoch 8/400, Participant 2: Loss = 1.6242\n",
      "Epoch 9/400, Participant 2: Loss = 1.4511\n",
      "Epoch 10/400, Participant 2: Loss = 1.2876\n",
      "Epoch 11/400, Participant 2: Loss = 1.1171\n",
      "Epoch 12/400, Participant 2: Loss = 0.9623\n",
      "Epoch 13/400, Participant 2: Loss = 0.8143\n",
      "Epoch 14/400, Participant 2: Loss = 0.6608\n",
      "Epoch 15/400, Participant 2: Loss = 0.5298\n",
      "Epoch 16/400, Participant 2: Loss = 0.4175\n",
      "Epoch 17/400, Participant 2: Loss = 0.3160\n",
      "Epoch 18/400, Participant 2: Loss = 0.2271\n",
      "Epoch 19/400, Participant 2: Loss = 0.1593\n",
      "Epoch 20/400, Participant 2: Loss = 0.1054\n",
      "Epoch 21/400, Participant 2: Loss = 0.0682\n",
      "Epoch 22/400, Participant 2: Loss = 0.0412\n",
      "Epoch 23/400, Participant 2: Loss = 0.0254\n",
      "Epoch 24/400, Participant 2: Loss = 0.0177\n",
      "Epoch 25/400, Participant 2: Loss = 0.0136\n",
      "Epoch 26/400, Participant 2: Loss = 0.0106\n",
      "Epoch 27/400, Participant 2: Loss = 0.0087\n",
      "Epoch 28/400, Participant 2: Loss = 0.0074\n",
      "Epoch 29/400, Participant 2: Loss = 0.0063\n",
      "Epoch 30/400, Participant 2: Loss = 0.0055\n",
      "Epoch 31/400, Participant 2: Loss = 0.0048\n",
      "Epoch 32/400, Participant 2: Loss = 0.0042\n",
      "Epoch 33/400, Participant 2: Loss = 0.0037\n",
      "Epoch 34/400, Participant 2: Loss = 0.0033\n",
      "Epoch 35/400, Participant 2: Loss = 0.0030\n",
      "Epoch 36/400, Participant 2: Loss = 0.0027\n",
      "Epoch 37/400, Participant 2: Loss = 0.0024\n",
      "Epoch 38/400, Participant 2: Loss = 0.0022\n",
      "Epoch 39/400, Participant 2: Loss = 0.0019\n",
      "Epoch 40/400, Participant 2: Loss = 0.0018\n",
      "Epoch 41/400, Participant 2: Loss = 0.0016\n",
      "Epoch 42/400, Participant 2: Loss = 0.0015\n",
      "Epoch 43/400, Participant 2: Loss = 0.0013\n",
      "Epoch 44/400, Participant 2: Loss = 0.0012\n",
      "Epoch 45/400, Participant 2: Loss = 0.0011\n",
      "Epoch 46/400, Participant 2: Loss = 0.0010\n",
      "Epoch 47/400, Participant 2: Loss = 0.0009\n",
      "Epoch 48/400, Participant 2: Loss = 0.0008\n",
      "Epoch 49/400, Participant 2: Loss = 0.0008\n",
      "Epoch 50/400, Participant 2: Loss = 0.0007\n",
      "Epoch 51/400, Participant 2: Loss = 0.0006\n",
      "Epoch 52/400, Participant 2: Loss = 0.0006\n",
      "Epoch 53/400, Participant 2: Loss = 0.0005\n",
      "Epoch 54/400, Participant 2: Loss = 0.0005\n",
      "Epoch 55/400, Participant 2: Loss = 0.0004\n",
      "Epoch 56/400, Participant 2: Loss = 0.0004\n",
      "Epoch 57/400, Participant 2: Loss = 0.0004\n",
      "Epoch 58/400, Participant 2: Loss = 0.0003\n",
      "Epoch 59/400, Participant 2: Loss = 0.0003\n",
      "Epoch 60/400, Participant 2: Loss = 0.0003\n",
      "Epoch 61/400, Participant 2: Loss = 0.0003\n",
      "Epoch 62/400, Participant 2: Loss = 0.0002\n",
      "Epoch 63/400, Participant 2: Loss = 0.0002\n",
      "Epoch 64/400, Participant 2: Loss = 0.0002\n",
      "Epoch 65/400, Participant 2: Loss = 0.0002\n",
      "Epoch 66/400, Participant 2: Loss = 0.0002\n",
      "Epoch 67/400, Participant 2: Loss = 0.0002\n",
      "Epoch 68/400, Participant 2: Loss = 0.0001\n",
      "Epoch 69/400, Participant 2: Loss = 0.0001\n",
      "Epoch 70/400, Participant 2: Loss = 0.0001\n",
      "Epoch 71/400, Participant 2: Loss = 0.0001\n",
      "Epoch 72/400, Participant 2: Loss = 0.0001\n",
      "Epoch 73/400, Participant 2: Loss = 0.0001\n",
      "Epoch 74/400, Participant 2: Loss = 0.0001\n",
      "Epoch 75/400, Participant 2: Loss = 0.0001\n",
      "Epoch 76/400, Participant 2: Loss = 0.0001\n",
      "Epoch 77/400, Participant 2: Loss = 0.0001\n",
      "Epoch 78/400, Participant 2: Loss = 0.0001\n",
      "Epoch 79/400, Participant 2: Loss = 0.0001\n",
      "Epoch 80/400, Participant 2: Loss = 0.0001\n",
      "Epoch 81/400, Participant 2: Loss = 0.0000\n",
      "Epoch 82/400, Participant 2: Loss = 0.0000\n",
      "Epoch 83/400, Participant 2: Loss = 0.0000\n",
      "Epoch 84/400, Participant 2: Loss = 0.0000\n",
      "Epoch 85/400, Participant 2: Loss = 0.0000\n",
      "Epoch 86/400, Participant 2: Loss = 0.0000\n",
      "Epoch 87/400, Participant 2: Loss = 0.0000\n",
      "Epoch 88/400, Participant 2: Loss = 0.0000\n",
      "Epoch 89/400, Participant 2: Loss = 0.0000\n",
      "Epoch 90/400, Participant 2: Loss = 0.0000\n",
      "Epoch 91/400, Participant 2: Loss = 0.0000\n",
      "Epoch 92/400, Participant 2: Loss = 0.0000\n",
      "Epoch 93/400, Participant 2: Loss = 0.0000\n",
      "Epoch 94/400, Participant 2: Loss = 0.0000\n",
      "Epoch 95/400, Participant 2: Loss = 0.0000\n",
      "Epoch 96/400, Participant 2: Loss = 0.0000\n",
      "Epoch 97/400, Participant 2: Loss = 0.0000\n",
      "Epoch 98/400, Participant 2: Loss = 0.0000\n",
      "Epoch 99/400, Participant 2: Loss = 0.0000\n",
      "Epoch 100/400, Participant 2: Loss = 0.0000\n",
      "Epoch 101/400, Participant 2: Loss = 0.0000\n",
      "Epoch 102/400, Participant 2: Loss = 0.0000\n",
      "Epoch 103/400, Participant 2: Loss = 0.0000\n",
      "Epoch 104/400, Participant 2: Loss = 0.0000\n",
      "Epoch 105/400, Participant 2: Loss = 0.0000\n",
      "Epoch 106/400, Participant 2: Loss = 0.0000\n",
      "Epoch 107/400, Participant 2: Loss = 0.0000\n",
      "Epoch 108/400, Participant 2: Loss = 0.0000\n",
      "Epoch 109/400, Participant 2: Loss = 0.0000\n",
      "Epoch 110/400, Participant 2: Loss = 0.0000\n",
      "Epoch 111/400, Participant 2: Loss = 0.0000\n",
      "Epoch 112/400, Participant 2: Loss = 0.0000\n",
      "Epoch 113/400, Participant 2: Loss = 0.0000\n",
      "Epoch 114/400, Participant 2: Loss = 0.0000\n",
      "Epoch 115/400, Participant 2: Loss = 0.0000\n",
      "Epoch 116/400, Participant 2: Loss = 0.0000\n",
      "Epoch 117/400, Participant 2: Loss = 0.0000\n",
      "Epoch 118/400, Participant 2: Loss = 0.0000\n",
      "Epoch 119/400, Participant 2: Loss = 0.0000\n",
      "Epoch 120/400, Participant 2: Loss = 0.0000\n",
      "Epoch 121/400, Participant 2: Loss = 0.0000\n",
      "Epoch 122/400, Participant 2: Loss = 0.0000\n",
      "Epoch 123/400, Participant 2: Loss = 0.0000\n",
      "Epoch 124/400, Participant 2: Loss = 0.0000\n",
      "Epoch 125/400, Participant 2: Loss = 0.0000\n",
      "Epoch 126/400, Participant 2: Loss = 0.0000\n",
      "Epoch 127/400, Participant 2: Loss = 0.0000\n",
      "Epoch 128/400, Participant 2: Loss = 0.0000\n",
      "Epoch 129/400, Participant 2: Loss = 0.0000\n",
      "Epoch 130/400, Participant 2: Loss = 0.0000\n",
      "Epoch 131/400, Participant 2: Loss = 0.0000\n",
      "Epoch 132/400, Participant 2: Loss = 0.0000\n",
      "Epoch 133/400, Participant 2: Loss = 0.0000\n",
      "Epoch 134/400, Participant 2: Loss = 0.0000\n",
      "Epoch 135/400, Participant 2: Loss = 0.0000\n",
      "Epoch 136/400, Participant 2: Loss = 0.0000\n",
      "Epoch 137/400, Participant 2: Loss = 0.0000\n",
      "Epoch 138/400, Participant 2: Loss = 0.0000\n",
      "Epoch 139/400, Participant 2: Loss = 0.0000\n",
      "Epoch 140/400, Participant 2: Loss = 0.0000\n",
      "Epoch 141/400, Participant 2: Loss = 0.0000\n",
      "Epoch 142/400, Participant 2: Loss = 0.0000\n",
      "Epoch 143/400, Participant 2: Loss = 0.0000\n",
      "Epoch 144/400, Participant 2: Loss = 0.0000\n",
      "Epoch 145/400, Participant 2: Loss = 0.0000\n",
      "Epoch 146/400, Participant 2: Loss = 0.0000\n",
      "Epoch 147/400, Participant 2: Loss = 0.0000\n",
      "Epoch 148/400, Participant 2: Loss = 0.0000\n",
      "Epoch 149/400, Participant 2: Loss = 0.0000\n",
      "Epoch 150/400, Participant 2: Loss = 0.0000\n",
      "Epoch 151/400, Participant 2: Loss = 0.0000\n",
      "Epoch 152/400, Participant 2: Loss = 0.0000\n",
      "Epoch 153/400, Participant 2: Loss = 0.0000\n",
      "Epoch 154/400, Participant 2: Loss = 0.0000\n",
      "Epoch 155/400, Participant 2: Loss = 0.0000\n",
      "Epoch 156/400, Participant 2: Loss = 0.0000\n",
      "Epoch 157/400, Participant 2: Loss = 0.0000\n",
      "Epoch 158/400, Participant 2: Loss = 0.0000\n",
      "Epoch 159/400, Participant 2: Loss = 0.0000\n",
      "Epoch 160/400, Participant 2: Loss = 0.0000\n",
      "Epoch 161/400, Participant 2: Loss = 0.0000\n",
      "Epoch 162/400, Participant 2: Loss = 0.0000\n",
      "Epoch 163/400, Participant 2: Loss = 0.0000\n",
      "Epoch 164/400, Participant 2: Loss = 0.0000\n",
      "Epoch 165/400, Participant 2: Loss = 0.0000\n",
      "Epoch 166/400, Participant 2: Loss = 0.0000\n",
      "Epoch 167/400, Participant 2: Loss = 0.0000\n",
      "Epoch 168/400, Participant 2: Loss = 0.0000\n",
      "Epoch 169/400, Participant 2: Loss = 0.0000\n",
      "Epoch 170/400, Participant 2: Loss = 0.0000\n",
      "Epoch 171/400, Participant 2: Loss = 0.0000\n",
      "Epoch 172/400, Participant 2: Loss = 1.8921\n",
      "Epoch 173/400, Participant 2: Loss = 0.3521\n",
      "Epoch 174/400, Participant 2: Loss = 0.0557\n",
      "Epoch 175/400, Participant 2: Loss = 0.0105\n",
      "Epoch 176/400, Participant 2: Loss = 0.0042\n",
      "Epoch 177/400, Participant 2: Loss = 0.0029\n",
      "Epoch 178/400, Participant 2: Loss = 0.0023\n",
      "Epoch 179/400, Participant 2: Loss = 0.0020\n",
      "Epoch 180/400, Participant 2: Loss = 0.0017\n",
      "Epoch 181/400, Participant 2: Loss = 0.0015\n",
      "Epoch 182/400, Participant 2: Loss = 0.0013\n",
      "Epoch 183/400, Participant 2: Loss = 0.0012\n",
      "Epoch 184/400, Participant 2: Loss = 0.0011\n",
      "Epoch 185/400, Participant 2: Loss = 0.0010\n",
      "Epoch 186/400, Participant 2: Loss = 0.0009\n",
      "Epoch 187/400, Participant 2: Loss = 0.0008\n",
      "Epoch 188/400, Participant 2: Loss = 0.0008\n",
      "Epoch 189/400, Participant 2: Loss = 0.0007\n",
      "Epoch 190/400, Participant 2: Loss = 0.0007\n",
      "Epoch 191/400, Participant 2: Loss = 0.0006\n",
      "Epoch 192/400, Participant 2: Loss = 0.0006\n",
      "Epoch 193/400, Participant 2: Loss = 0.0005\n",
      "Epoch 194/400, Participant 2: Loss = 0.0005\n",
      "Epoch 195/400, Participant 2: Loss = 0.0005\n",
      "Epoch 196/400, Participant 2: Loss = 0.0004\n",
      "Epoch 197/400, Participant 2: Loss = 0.0004\n",
      "Epoch 198/400, Participant 2: Loss = 0.0004\n",
      "Epoch 199/400, Participant 2: Loss = 0.0004\n",
      "Epoch 200/400, Participant 2: Loss = 0.0003\n",
      "Epoch 201/400, Participant 2: Loss = 0.0003\n",
      "Epoch 202/400, Participant 2: Loss = 0.0003\n",
      "Epoch 203/400, Participant 2: Loss = 0.0003\n",
      "Epoch 204/400, Participant 2: Loss = 0.0003\n",
      "Epoch 205/400, Participant 2: Loss = 0.0002\n",
      "Epoch 206/400, Participant 2: Loss = 0.0002\n",
      "Epoch 207/400, Participant 2: Loss = 0.0002\n",
      "Epoch 208/400, Participant 2: Loss = 0.0002\n",
      "Epoch 209/400, Participant 2: Loss = 0.0002\n",
      "Epoch 210/400, Participant 2: Loss = 0.0002\n",
      "Epoch 211/400, Participant 2: Loss = 0.0002\n",
      "Epoch 212/400, Participant 2: Loss = 0.0002\n",
      "Epoch 213/400, Participant 2: Loss = 0.0002\n",
      "Epoch 214/400, Participant 2: Loss = 0.0001\n",
      "Epoch 215/400, Participant 2: Loss = 0.0001\n",
      "Epoch 216/400, Participant 2: Loss = 0.0001\n",
      "Epoch 217/400, Participant 2: Loss = 0.0001\n",
      "Epoch 218/400, Participant 2: Loss = 0.0001\n",
      "Epoch 219/400, Participant 2: Loss = 0.0001\n",
      "Epoch 220/400, Participant 2: Loss = 0.0001\n",
      "Epoch 221/400, Participant 2: Loss = 0.0001\n",
      "Epoch 222/400, Participant 2: Loss = 0.0001\n",
      "Epoch 223/400, Participant 2: Loss = 0.0001\n",
      "Epoch 224/400, Participant 2: Loss = 0.0001\n",
      "Epoch 225/400, Participant 2: Loss = 0.0001\n",
      "Epoch 226/400, Participant 2: Loss = 0.0001\n",
      "Epoch 227/400, Participant 2: Loss = 0.0001\n",
      "Epoch 228/400, Participant 2: Loss = 0.0001\n",
      "Epoch 229/400, Participant 2: Loss = 0.0001\n",
      "Epoch 230/400, Participant 2: Loss = 0.0001\n",
      "Epoch 231/400, Participant 2: Loss = 0.0001\n",
      "Epoch 232/400, Participant 2: Loss = 0.0000\n",
      "Epoch 233/400, Participant 2: Loss = 0.0000\n",
      "Epoch 234/400, Participant 2: Loss = 0.0000\n",
      "Epoch 235/400, Participant 2: Loss = 0.0000\n",
      "Epoch 236/400, Participant 2: Loss = 0.0000\n",
      "Epoch 237/400, Participant 2: Loss = 0.0000\n",
      "Epoch 238/400, Participant 2: Loss = 0.0000\n",
      "Epoch 239/400, Participant 2: Loss = 0.0000\n",
      "Epoch 240/400, Participant 2: Loss = 0.0000\n",
      "Epoch 241/400, Participant 2: Loss = 0.0000\n",
      "Epoch 242/400, Participant 2: Loss = 0.0000\n",
      "Epoch 243/400, Participant 2: Loss = 0.0000\n",
      "Epoch 244/400, Participant 2: Loss = 0.0000\n",
      "Epoch 245/400, Participant 2: Loss = 0.0000\n",
      "Epoch 246/400, Participant 2: Loss = 0.0000\n",
      "Epoch 247/400, Participant 2: Loss = 0.0000\n",
      "Epoch 248/400, Participant 2: Loss = 0.0000\n",
      "Epoch 249/400, Participant 2: Loss = 0.0000\n",
      "Epoch 250/400, Participant 2: Loss = 0.0000\n",
      "Epoch 251/400, Participant 2: Loss = 0.0000\n",
      "Epoch 252/400, Participant 2: Loss = 0.0000\n",
      "Epoch 253/400, Participant 2: Loss = 0.0000\n",
      "Epoch 254/400, Participant 2: Loss = 0.0000\n",
      "Epoch 255/400, Participant 2: Loss = 0.0000\n",
      "Epoch 256/400, Participant 2: Loss = 0.0000\n",
      "Epoch 257/400, Participant 2: Loss = 0.0000\n",
      "Epoch 258/400, Participant 2: Loss = 0.0000\n",
      "Epoch 259/400, Participant 2: Loss = 0.0000\n",
      "Epoch 260/400, Participant 2: Loss = 0.0000\n",
      "Epoch 261/400, Participant 2: Loss = 0.0000\n",
      "Epoch 262/400, Participant 2: Loss = 0.0000\n",
      "Epoch 263/400, Participant 2: Loss = 0.0000\n",
      "Epoch 264/400, Participant 2: Loss = 0.0000\n",
      "Epoch 265/400, Participant 2: Loss = 0.0000\n",
      "Epoch 266/400, Participant 2: Loss = 0.0000\n",
      "Epoch 267/400, Participant 2: Loss = 0.0000\n",
      "Epoch 268/400, Participant 2: Loss = 0.0000\n",
      "Epoch 269/400, Participant 2: Loss = 0.0000\n",
      "Epoch 270/400, Participant 2: Loss = 0.0000\n",
      "Epoch 271/400, Participant 2: Loss = 0.0000\n",
      "Epoch 272/400, Participant 2: Loss = 0.0000\n",
      "Epoch 273/400, Participant 2: Loss = 0.0000\n",
      "Epoch 274/400, Participant 2: Loss = 0.0000\n",
      "Epoch 275/400, Participant 2: Loss = 0.0000\n",
      "Epoch 276/400, Participant 2: Loss = 0.0000\n",
      "Epoch 277/400, Participant 2: Loss = 0.0000\n",
      "Epoch 278/400, Participant 2: Loss = 0.0000\n",
      "Epoch 279/400, Participant 2: Loss = 0.0000\n",
      "Epoch 280/400, Participant 2: Loss = 0.0000\n",
      "Epoch 281/400, Participant 2: Loss = 0.0000\n",
      "Epoch 282/400, Participant 2: Loss = 0.0000\n",
      "Epoch 283/400, Participant 2: Loss = 0.0000\n",
      "Epoch 284/400, Participant 2: Loss = 0.0000\n",
      "Epoch 285/400, Participant 2: Loss = 0.0000\n",
      "Epoch 286/400, Participant 2: Loss = 0.0000\n",
      "Epoch 287/400, Participant 2: Loss = 0.0000\n",
      "Epoch 288/400, Participant 2: Loss = 0.0000\n",
      "Epoch 289/400, Participant 2: Loss = 0.0000\n",
      "Epoch 290/400, Participant 2: Loss = 0.0000\n",
      "Epoch 291/400, Participant 2: Loss = 0.0000\n",
      "Epoch 292/400, Participant 2: Loss = 0.0000\n",
      "Epoch 293/400, Participant 2: Loss = 0.0000\n",
      "Epoch 294/400, Participant 2: Loss = 0.0000\n",
      "Epoch 295/400, Participant 2: Loss = 0.0000\n",
      "Epoch 296/400, Participant 2: Loss = 0.0000\n",
      "Epoch 297/400, Participant 2: Loss = 0.0000\n",
      "Epoch 298/400, Participant 2: Loss = 0.0000\n",
      "Epoch 299/400, Participant 2: Loss = 0.0000\n",
      "Epoch 300/400, Participant 2: Loss = 0.0000\n",
      "Epoch 301/400, Participant 2: Loss = 0.0000\n",
      "Epoch 302/400, Participant 2: Loss = 0.0000\n",
      "Epoch 303/400, Participant 2: Loss = 0.0000\n",
      "Epoch 304/400, Participant 2: Loss = 0.0000\n",
      "Epoch 305/400, Participant 2: Loss = 0.0000\n",
      "Epoch 306/400, Participant 2: Loss = 0.0000\n",
      "Epoch 307/400, Participant 2: Loss = 0.0000\n",
      "Epoch 308/400, Participant 2: Loss = 0.0000\n",
      "Epoch 309/400, Participant 2: Loss = 0.0000\n",
      "Epoch 310/400, Participant 2: Loss = 0.0000\n",
      "Epoch 311/400, Participant 2: Loss = 0.0000\n",
      "Epoch 312/400, Participant 2: Loss = 0.0000\n",
      "Epoch 313/400, Participant 2: Loss = 0.0000\n",
      "Epoch 314/400, Participant 2: Loss = 0.0000\n",
      "Epoch 315/400, Participant 2: Loss = 0.0000\n",
      "Epoch 316/400, Participant 2: Loss = 0.0000\n",
      "Epoch 317/400, Participant 2: Loss = 0.0000\n",
      "Epoch 318/400, Participant 2: Loss = 0.0000\n",
      "Epoch 319/400, Participant 2: Loss = 0.0000\n",
      "Epoch 320/400, Participant 2: Loss = 0.0000\n",
      "Epoch 321/400, Participant 2: Loss = 0.0000\n",
      "Epoch 322/400, Participant 2: Loss = 0.0000\n",
      "Epoch 323/400, Participant 2: Loss = 0.0000\n",
      "Epoch 324/400, Participant 2: Loss = 0.0000\n",
      "Epoch 325/400, Participant 2: Loss = 0.0000\n",
      "Epoch 326/400, Participant 2: Loss = 0.0000\n",
      "Epoch 327/400, Participant 2: Loss = 0.0000\n",
      "Epoch 328/400, Participant 2: Loss = 0.0695\n",
      "Epoch 329/400, Participant 2: Loss = 1.3867\n",
      "Epoch 330/400, Participant 2: Loss = 0.1861\n",
      "Epoch 331/400, Participant 2: Loss = 0.0238\n",
      "Epoch 332/400, Participant 2: Loss = 0.0046\n",
      "Epoch 333/400, Participant 2: Loss = 0.0023\n",
      "Epoch 334/400, Participant 2: Loss = 0.0017\n",
      "Epoch 335/400, Participant 2: Loss = 0.0015\n",
      "Epoch 336/400, Participant 2: Loss = 0.0013\n",
      "Epoch 337/400, Participant 2: Loss = 0.0011\n",
      "Epoch 338/400, Participant 2: Loss = 0.0010\n",
      "Epoch 339/400, Participant 2: Loss = 0.0009\n",
      "Epoch 340/400, Participant 2: Loss = 0.0008\n",
      "Epoch 341/400, Participant 2: Loss = 0.0007\n",
      "Epoch 342/400, Participant 2: Loss = 0.0007\n",
      "Epoch 343/400, Participant 2: Loss = 0.0006\n",
      "Epoch 344/400, Participant 2: Loss = 0.0006\n",
      "Epoch 345/400, Participant 2: Loss = 0.0006\n",
      "Epoch 346/400, Participant 2: Loss = 0.0005\n",
      "Epoch 347/400, Participant 2: Loss = 0.0005\n",
      "Epoch 348/400, Participant 2: Loss = 0.0005\n",
      "Epoch 349/400, Participant 2: Loss = 0.0004\n",
      "Epoch 350/400, Participant 2: Loss = 0.0004\n",
      "Epoch 351/400, Participant 2: Loss = 0.0004\n",
      "Epoch 352/400, Participant 2: Loss = 0.0004\n",
      "Epoch 353/400, Participant 2: Loss = 0.0003\n",
      "Epoch 354/400, Participant 2: Loss = 0.0003\n",
      "Epoch 355/400, Participant 2: Loss = 0.0003\n",
      "Epoch 356/400, Participant 2: Loss = 0.0003\n",
      "Epoch 357/400, Participant 2: Loss = 0.0003\n",
      "Epoch 358/400, Participant 2: Loss = 0.0003\n",
      "Epoch 359/400, Participant 2: Loss = 0.0002\n",
      "Epoch 360/400, Participant 2: Loss = 0.0002\n",
      "Epoch 361/400, Participant 2: Loss = 0.0002\n",
      "Epoch 362/400, Participant 2: Loss = 0.0002\n",
      "Epoch 363/400, Participant 2: Loss = 0.0002\n",
      "Epoch 364/400, Participant 2: Loss = 0.0002\n",
      "Epoch 365/400, Participant 2: Loss = 0.0002\n",
      "Epoch 366/400, Participant 2: Loss = 0.0002\n",
      "Epoch 367/400, Participant 2: Loss = 0.0001\n",
      "Epoch 368/400, Participant 2: Loss = 0.0001\n",
      "Epoch 369/400, Participant 2: Loss = 0.0001\n",
      "Epoch 370/400, Participant 2: Loss = 0.0001\n",
      "Epoch 371/400, Participant 2: Loss = 0.0001\n",
      "Epoch 372/400, Participant 2: Loss = 0.0001\n",
      "Epoch 373/400, Participant 2: Loss = 0.0001\n",
      "Epoch 374/400, Participant 2: Loss = 0.0001\n",
      "Epoch 375/400, Participant 2: Loss = 0.0001\n",
      "Epoch 376/400, Participant 2: Loss = 0.0001\n",
      "Epoch 377/400, Participant 2: Loss = 0.0001\n",
      "Epoch 378/400, Participant 2: Loss = 0.0001\n",
      "Epoch 379/400, Participant 2: Loss = 0.0001\n",
      "Epoch 380/400, Participant 2: Loss = 0.0001\n",
      "Epoch 381/400, Participant 2: Loss = 0.0001\n",
      "Epoch 382/400, Participant 2: Loss = 0.0001\n",
      "Epoch 383/400, Participant 2: Loss = 0.0001\n",
      "Epoch 384/400, Participant 2: Loss = 0.0001\n",
      "Epoch 385/400, Participant 2: Loss = 0.0001\n",
      "Epoch 386/400, Participant 2: Loss = 0.0001\n",
      "Epoch 387/400, Participant 2: Loss = 0.0000\n",
      "Epoch 388/400, Participant 2: Loss = 0.0000\n",
      "Epoch 389/400, Participant 2: Loss = 0.0000\n",
      "Epoch 390/400, Participant 2: Loss = 0.0000\n",
      "Epoch 391/400, Participant 2: Loss = 0.0000\n",
      "Epoch 392/400, Participant 2: Loss = 0.0000\n",
      "Epoch 393/400, Participant 2: Loss = 0.0000\n",
      "Epoch 394/400, Participant 2: Loss = 0.0000\n",
      "Epoch 395/400, Participant 2: Loss = 0.0000\n",
      "Epoch 396/400, Participant 2: Loss = 0.0000\n",
      "Epoch 397/400, Participant 2: Loss = 0.0000\n",
      "Epoch 398/400, Participant 2: Loss = 0.0000\n",
      "Epoch 399/400, Participant 2: Loss = 0.0000\n",
      "Epoch 400/400, Participant 2: Loss = 0.0000\n",
      "LOPO Test Participant 2: Accuracy = 13.12%, F1 Score = 0.12\n",
      "Training excluding Participant 7\n",
      "Epoch 1/400, Participant 7: Loss = 2.9929\n",
      "Epoch 2/400, Participant 7: Loss = 2.6804\n",
      "Epoch 3/400, Participant 7: Loss = 2.4975\n",
      "Epoch 4/400, Participant 7: Loss = 2.3297\n",
      "Epoch 5/400, Participant 7: Loss = 2.1654\n",
      "Epoch 6/400, Participant 7: Loss = 2.0021\n",
      "Epoch 7/400, Participant 7: Loss = 1.8318\n",
      "Epoch 8/400, Participant 7: Loss = 1.6680\n",
      "Epoch 9/400, Participant 7: Loss = 1.4818\n",
      "Epoch 10/400, Participant 7: Loss = 1.3123\n",
      "Epoch 11/400, Participant 7: Loss = 1.1454\n",
      "Epoch 12/400, Participant 7: Loss = 0.9812\n",
      "Epoch 13/400, Participant 7: Loss = 0.8239\n",
      "Epoch 14/400, Participant 7: Loss = 0.6866\n",
      "Epoch 15/400, Participant 7: Loss = 0.5578\n",
      "Epoch 16/400, Participant 7: Loss = 0.4392\n",
      "Epoch 17/400, Participant 7: Loss = 0.3387\n",
      "Epoch 18/400, Participant 7: Loss = 0.2471\n",
      "Epoch 19/400, Participant 7: Loss = 0.1765\n",
      "Epoch 20/400, Participant 7: Loss = 0.1200\n",
      "Epoch 21/400, Participant 7: Loss = 0.0795\n",
      "Epoch 22/400, Participant 7: Loss = 0.0522\n",
      "Epoch 23/400, Participant 7: Loss = 0.0329\n",
      "Epoch 24/400, Participant 7: Loss = 0.0225\n",
      "Epoch 25/400, Participant 7: Loss = 0.0159\n",
      "Epoch 26/400, Participant 7: Loss = 0.0124\n",
      "Epoch 27/400, Participant 7: Loss = 0.0102\n",
      "Epoch 28/400, Participant 7: Loss = 0.0085\n",
      "Epoch 29/400, Participant 7: Loss = 0.0072\n",
      "Epoch 30/400, Participant 7: Loss = 0.0062\n",
      "Epoch 31/400, Participant 7: Loss = 0.0054\n",
      "Epoch 32/400, Participant 7: Loss = 0.0047\n",
      "Epoch 33/400, Participant 7: Loss = 0.0042\n",
      "Epoch 34/400, Participant 7: Loss = 0.0036\n",
      "Epoch 35/400, Participant 7: Loss = 0.0032\n",
      "Epoch 36/400, Participant 7: Loss = 0.0029\n",
      "Epoch 37/400, Participant 7: Loss = 0.0026\n",
      "Epoch 38/400, Participant 7: Loss = 0.0023\n",
      "Epoch 39/400, Participant 7: Loss = 0.0021\n",
      "Epoch 40/400, Participant 7: Loss = 0.0019\n",
      "Epoch 41/400, Participant 7: Loss = 0.0017\n",
      "Epoch 42/400, Participant 7: Loss = 0.0015\n",
      "Epoch 43/400, Participant 7: Loss = 0.0014\n",
      "Epoch 44/400, Participant 7: Loss = 0.0012\n",
      "Epoch 45/400, Participant 7: Loss = 0.0011\n",
      "Epoch 46/400, Participant 7: Loss = 0.0010\n",
      "Epoch 47/400, Participant 7: Loss = 0.0009\n",
      "Epoch 48/400, Participant 7: Loss = 0.0008\n",
      "Epoch 49/400, Participant 7: Loss = 0.0008\n",
      "Epoch 50/400, Participant 7: Loss = 0.0007\n",
      "Epoch 51/400, Participant 7: Loss = 0.0006\n",
      "Epoch 52/400, Participant 7: Loss = 0.0006\n",
      "Epoch 53/400, Participant 7: Loss = 0.0005\n",
      "Epoch 54/400, Participant 7: Loss = 0.0005\n",
      "Epoch 55/400, Participant 7: Loss = 0.0005\n",
      "Epoch 56/400, Participant 7: Loss = 0.0004\n",
      "Epoch 57/400, Participant 7: Loss = 0.0004\n",
      "Epoch 58/400, Participant 7: Loss = 0.0004\n",
      "Epoch 59/400, Participant 7: Loss = 0.0003\n",
      "Epoch 60/400, Participant 7: Loss = 0.0003\n",
      "Epoch 61/400, Participant 7: Loss = 0.0003\n",
      "Epoch 62/400, Participant 7: Loss = 0.0002\n",
      "Epoch 63/400, Participant 7: Loss = 0.0002\n",
      "Epoch 64/400, Participant 7: Loss = 0.0002\n",
      "Epoch 65/400, Participant 7: Loss = 0.0002\n",
      "Epoch 66/400, Participant 7: Loss = 0.0002\n",
      "Epoch 67/400, Participant 7: Loss = 0.0002\n",
      "Epoch 68/400, Participant 7: Loss = 0.0002\n",
      "Epoch 69/400, Participant 7: Loss = 0.0001\n",
      "Epoch 70/400, Participant 7: Loss = 0.0001\n",
      "Epoch 71/400, Participant 7: Loss = 0.0001\n",
      "Epoch 72/400, Participant 7: Loss = 0.0001\n",
      "Epoch 73/400, Participant 7: Loss = 0.0001\n",
      "Epoch 74/400, Participant 7: Loss = 0.0001\n",
      "Epoch 75/400, Participant 7: Loss = 0.0001\n",
      "Epoch 76/400, Participant 7: Loss = 0.0001\n",
      "Epoch 77/400, Participant 7: Loss = 0.0001\n",
      "Epoch 78/400, Participant 7: Loss = 0.0001\n",
      "Epoch 79/400, Participant 7: Loss = 0.0001\n",
      "Epoch 80/400, Participant 7: Loss = 0.0001\n",
      "Epoch 81/400, Participant 7: Loss = 0.0001\n",
      "Epoch 82/400, Participant 7: Loss = 0.0000\n",
      "Epoch 83/400, Participant 7: Loss = 0.0000\n",
      "Epoch 84/400, Participant 7: Loss = 0.0000\n",
      "Epoch 85/400, Participant 7: Loss = 0.0000\n",
      "Epoch 86/400, Participant 7: Loss = 0.0000\n",
      "Epoch 87/400, Participant 7: Loss = 0.0000\n",
      "Epoch 88/400, Participant 7: Loss = 0.0000\n",
      "Epoch 89/400, Participant 7: Loss = 0.0000\n",
      "Epoch 90/400, Participant 7: Loss = 0.0000\n",
      "Epoch 91/400, Participant 7: Loss = 0.0000\n",
      "Epoch 92/400, Participant 7: Loss = 0.0000\n",
      "Epoch 93/400, Participant 7: Loss = 0.0000\n",
      "Epoch 94/400, Participant 7: Loss = 0.0000\n",
      "Epoch 95/400, Participant 7: Loss = 0.0000\n",
      "Epoch 96/400, Participant 7: Loss = 0.0000\n",
      "Epoch 97/400, Participant 7: Loss = 0.0000\n",
      "Epoch 98/400, Participant 7: Loss = 0.0000\n",
      "Epoch 99/400, Participant 7: Loss = 0.0000\n",
      "Epoch 100/400, Participant 7: Loss = 0.0000\n",
      "Epoch 101/400, Participant 7: Loss = 0.0000\n",
      "Epoch 102/400, Participant 7: Loss = 0.0000\n",
      "Epoch 103/400, Participant 7: Loss = 0.0000\n",
      "Epoch 104/400, Participant 7: Loss = 0.0000\n",
      "Epoch 105/400, Participant 7: Loss = 0.0000\n",
      "Epoch 106/400, Participant 7: Loss = 0.0000\n",
      "Epoch 107/400, Participant 7: Loss = 0.0000\n",
      "Epoch 108/400, Participant 7: Loss = 0.0000\n",
      "Epoch 109/400, Participant 7: Loss = 0.0000\n",
      "Epoch 110/400, Participant 7: Loss = 0.0000\n",
      "Epoch 111/400, Participant 7: Loss = 0.0000\n",
      "Epoch 112/400, Participant 7: Loss = 0.0000\n",
      "Epoch 113/400, Participant 7: Loss = 0.0000\n",
      "Epoch 114/400, Participant 7: Loss = 0.0000\n",
      "Epoch 115/400, Participant 7: Loss = 0.0000\n",
      "Epoch 116/400, Participant 7: Loss = 0.0000\n",
      "Epoch 117/400, Participant 7: Loss = 0.0000\n",
      "Epoch 118/400, Participant 7: Loss = 0.0000\n",
      "Epoch 119/400, Participant 7: Loss = 0.0000\n",
      "Epoch 120/400, Participant 7: Loss = 0.0000\n",
      "Epoch 121/400, Participant 7: Loss = 0.0000\n",
      "Epoch 122/400, Participant 7: Loss = 0.0000\n",
      "Epoch 123/400, Participant 7: Loss = 0.0000\n",
      "Epoch 124/400, Participant 7: Loss = 0.0000\n",
      "Epoch 125/400, Participant 7: Loss = 0.0000\n",
      "Epoch 126/400, Participant 7: Loss = 0.0000\n",
      "Epoch 127/400, Participant 7: Loss = 0.0000\n",
      "Epoch 128/400, Participant 7: Loss = 0.0000\n",
      "Epoch 129/400, Participant 7: Loss = 0.0000\n",
      "Epoch 130/400, Participant 7: Loss = 0.0000\n",
      "Epoch 131/400, Participant 7: Loss = 0.0000\n",
      "Epoch 132/400, Participant 7: Loss = 0.0000\n",
      "Epoch 133/400, Participant 7: Loss = 0.0000\n",
      "Epoch 134/400, Participant 7: Loss = 0.0000\n",
      "Epoch 135/400, Participant 7: Loss = 0.0000\n",
      "Epoch 136/400, Participant 7: Loss = 0.0000\n",
      "Epoch 137/400, Participant 7: Loss = 0.0000\n",
      "Epoch 138/400, Participant 7: Loss = 0.0000\n",
      "Epoch 139/400, Participant 7: Loss = 0.0000\n",
      "Epoch 140/400, Participant 7: Loss = 0.0000\n",
      "Epoch 141/400, Participant 7: Loss = 0.0000\n",
      "Epoch 142/400, Participant 7: Loss = 0.0000\n",
      "Epoch 143/400, Participant 7: Loss = 0.0000\n",
      "Epoch 144/400, Participant 7: Loss = 0.0000\n",
      "Epoch 145/400, Participant 7: Loss = 0.0000\n",
      "Epoch 146/400, Participant 7: Loss = 0.0000\n",
      "Epoch 147/400, Participant 7: Loss = 0.0000\n",
      "Epoch 148/400, Participant 7: Loss = 0.0000\n",
      "Epoch 149/400, Participant 7: Loss = 0.0000\n",
      "Epoch 150/400, Participant 7: Loss = 0.0000\n",
      "Epoch 151/400, Participant 7: Loss = 0.0000\n",
      "Epoch 152/400, Participant 7: Loss = 0.0000\n",
      "Epoch 153/400, Participant 7: Loss = 0.0000\n",
      "Epoch 154/400, Participant 7: Loss = 0.0000\n",
      "Epoch 155/400, Participant 7: Loss = 0.0000\n",
      "Epoch 156/400, Participant 7: Loss = 0.0000\n",
      "Epoch 157/400, Participant 7: Loss = 0.0000\n",
      "Epoch 158/400, Participant 7: Loss = 0.0000\n",
      "Epoch 159/400, Participant 7: Loss = 0.0000\n",
      "Epoch 160/400, Participant 7: Loss = 0.0000\n",
      "Epoch 161/400, Participant 7: Loss = 0.0000\n",
      "Epoch 162/400, Participant 7: Loss = 0.0000\n",
      "Epoch 163/400, Participant 7: Loss = 0.0000\n",
      "Epoch 164/400, Participant 7: Loss = 0.0000\n",
      "Epoch 165/400, Participant 7: Loss = 0.0000\n",
      "Epoch 166/400, Participant 7: Loss = 0.0000\n",
      "Epoch 167/400, Participant 7: Loss = 0.0000\n",
      "Epoch 168/400, Participant 7: Loss = 0.0000\n",
      "Epoch 169/400, Participant 7: Loss = 0.0000\n",
      "Epoch 170/400, Participant 7: Loss = 0.0000\n",
      "Epoch 171/400, Participant 7: Loss = 0.0120\n",
      "Epoch 172/400, Participant 7: Loss = 1.7864\n",
      "Epoch 173/400, Participant 7: Loss = 0.3462\n",
      "Epoch 174/400, Participant 7: Loss = 0.0600\n",
      "Epoch 175/400, Participant 7: Loss = 0.0106\n",
      "Epoch 176/400, Participant 7: Loss = 0.0038\n",
      "Epoch 177/400, Participant 7: Loss = 0.0026\n",
      "Epoch 178/400, Participant 7: Loss = 0.0021\n",
      "Epoch 179/400, Participant 7: Loss = 0.0018\n",
      "Epoch 180/400, Participant 7: Loss = 0.0016\n",
      "Epoch 181/400, Participant 7: Loss = 0.0014\n",
      "Epoch 182/400, Participant 7: Loss = 0.0012\n",
      "Epoch 183/400, Participant 7: Loss = 0.0011\n",
      "Epoch 184/400, Participant 7: Loss = 0.0010\n",
      "Epoch 185/400, Participant 7: Loss = 0.0009\n",
      "Epoch 186/400, Participant 7: Loss = 0.0009\n",
      "Epoch 187/400, Participant 7: Loss = 0.0008\n",
      "Epoch 188/400, Participant 7: Loss = 0.0007\n",
      "Epoch 189/400, Participant 7: Loss = 0.0007\n",
      "Epoch 190/400, Participant 7: Loss = 0.0006\n",
      "Epoch 191/400, Participant 7: Loss = 0.0006\n",
      "Epoch 192/400, Participant 7: Loss = 0.0006\n",
      "Epoch 193/400, Participant 7: Loss = 0.0005\n",
      "Epoch 194/400, Participant 7: Loss = 0.0005\n",
      "Epoch 195/400, Participant 7: Loss = 0.0004\n",
      "Epoch 196/400, Participant 7: Loss = 0.0004\n",
      "Epoch 197/400, Participant 7: Loss = 0.0004\n",
      "Epoch 198/400, Participant 7: Loss = 0.0004\n",
      "Epoch 199/400, Participant 7: Loss = 0.0003\n",
      "Epoch 200/400, Participant 7: Loss = 0.0003\n",
      "Epoch 201/400, Participant 7: Loss = 0.0003\n",
      "Epoch 202/400, Participant 7: Loss = 0.0003\n",
      "Epoch 203/400, Participant 7: Loss = 0.0003\n",
      "Epoch 204/400, Participant 7: Loss = 0.0003\n",
      "Epoch 205/400, Participant 7: Loss = 0.0002\n",
      "Epoch 206/400, Participant 7: Loss = 0.0002\n",
      "Epoch 207/400, Participant 7: Loss = 0.0002\n",
      "Epoch 208/400, Participant 7: Loss = 0.0002\n",
      "Epoch 209/400, Participant 7: Loss = 0.0002\n",
      "Epoch 210/400, Participant 7: Loss = 0.0002\n",
      "Epoch 211/400, Participant 7: Loss = 0.0002\n",
      "Epoch 212/400, Participant 7: Loss = 0.0002\n",
      "Epoch 213/400, Participant 7: Loss = 0.0001\n",
      "Epoch 214/400, Participant 7: Loss = 0.0001\n",
      "Epoch 215/400, Participant 7: Loss = 0.0001\n",
      "Epoch 216/400, Participant 7: Loss = 0.0001\n",
      "Epoch 217/400, Participant 7: Loss = 0.0001\n",
      "Epoch 218/400, Participant 7: Loss = 0.0001\n",
      "Epoch 219/400, Participant 7: Loss = 0.0001\n",
      "Epoch 220/400, Participant 7: Loss = 0.0001\n",
      "Epoch 221/400, Participant 7: Loss = 0.0001\n",
      "Epoch 222/400, Participant 7: Loss = 0.0001\n",
      "Epoch 223/400, Participant 7: Loss = 0.0001\n",
      "Epoch 224/400, Participant 7: Loss = 0.0001\n",
      "Epoch 225/400, Participant 7: Loss = 0.0001\n",
      "Epoch 226/400, Participant 7: Loss = 0.0001\n",
      "Epoch 227/400, Participant 7: Loss = 0.0001\n",
      "Epoch 228/400, Participant 7: Loss = 0.0001\n",
      "Epoch 229/400, Participant 7: Loss = 0.0001\n",
      "Epoch 230/400, Participant 7: Loss = 0.0001\n",
      "Epoch 231/400, Participant 7: Loss = 0.0001\n",
      "Epoch 232/400, Participant 7: Loss = 0.0001\n",
      "Epoch 233/400, Participant 7: Loss = 0.0000\n",
      "Epoch 234/400, Participant 7: Loss = 0.0000\n",
      "Epoch 235/400, Participant 7: Loss = 0.0000\n",
      "Epoch 236/400, Participant 7: Loss = 0.0000\n",
      "Epoch 237/400, Participant 7: Loss = 0.0000\n",
      "Epoch 238/400, Participant 7: Loss = 0.0000\n",
      "Epoch 239/400, Participant 7: Loss = 0.0000\n",
      "Epoch 240/400, Participant 7: Loss = 0.0000\n",
      "Epoch 241/400, Participant 7: Loss = 0.0000\n",
      "Epoch 242/400, Participant 7: Loss = 0.0000\n",
      "Epoch 243/400, Participant 7: Loss = 0.0000\n",
      "Epoch 244/400, Participant 7: Loss = 0.0000\n",
      "Epoch 245/400, Participant 7: Loss = 0.0000\n",
      "Epoch 246/400, Participant 7: Loss = 0.0000\n",
      "Epoch 247/400, Participant 7: Loss = 0.0000\n",
      "Epoch 248/400, Participant 7: Loss = 0.0000\n",
      "Epoch 249/400, Participant 7: Loss = 0.0000\n",
      "Epoch 250/400, Participant 7: Loss = 0.0000\n",
      "Epoch 251/400, Participant 7: Loss = 0.0000\n",
      "Epoch 252/400, Participant 7: Loss = 0.0000\n",
      "Epoch 253/400, Participant 7: Loss = 0.0000\n",
      "Epoch 254/400, Participant 7: Loss = 0.0000\n",
      "Epoch 255/400, Participant 7: Loss = 0.0000\n",
      "Epoch 256/400, Participant 7: Loss = 0.0000\n",
      "Epoch 257/400, Participant 7: Loss = 0.0000\n",
      "Epoch 258/400, Participant 7: Loss = 0.0000\n",
      "Epoch 259/400, Participant 7: Loss = 0.0000\n",
      "Epoch 260/400, Participant 7: Loss = 0.0000\n",
      "Epoch 261/400, Participant 7: Loss = 0.0000\n",
      "Epoch 262/400, Participant 7: Loss = 0.0000\n",
      "Epoch 263/400, Participant 7: Loss = 0.0000\n",
      "Epoch 264/400, Participant 7: Loss = 0.0000\n",
      "Epoch 265/400, Participant 7: Loss = 0.0000\n",
      "Epoch 266/400, Participant 7: Loss = 0.0000\n",
      "Epoch 267/400, Participant 7: Loss = 0.0000\n",
      "Epoch 268/400, Participant 7: Loss = 0.0000\n",
      "Epoch 269/400, Participant 7: Loss = 0.0000\n",
      "Epoch 270/400, Participant 7: Loss = 0.0000\n",
      "Epoch 271/400, Participant 7: Loss = 0.0000\n",
      "Epoch 272/400, Participant 7: Loss = 0.0000\n",
      "Epoch 273/400, Participant 7: Loss = 0.0000\n",
      "Epoch 274/400, Participant 7: Loss = 0.0000\n",
      "Epoch 275/400, Participant 7: Loss = 0.0000\n",
      "Epoch 276/400, Participant 7: Loss = 0.0000\n",
      "Epoch 277/400, Participant 7: Loss = 0.0000\n",
      "Epoch 278/400, Participant 7: Loss = 0.0000\n",
      "Epoch 279/400, Participant 7: Loss = 0.0000\n",
      "Epoch 280/400, Participant 7: Loss = 0.0000\n",
      "Epoch 281/400, Participant 7: Loss = 0.0000\n",
      "Epoch 282/400, Participant 7: Loss = 0.0000\n",
      "Epoch 283/400, Participant 7: Loss = 0.0000\n",
      "Epoch 284/400, Participant 7: Loss = 0.0000\n",
      "Epoch 285/400, Participant 7: Loss = 0.0000\n",
      "Epoch 286/400, Participant 7: Loss = 0.0000\n",
      "Epoch 287/400, Participant 7: Loss = 0.0000\n",
      "Epoch 288/400, Participant 7: Loss = 0.0000\n",
      "Epoch 289/400, Participant 7: Loss = 0.0000\n",
      "Epoch 290/400, Participant 7: Loss = 0.0000\n",
      "Epoch 291/400, Participant 7: Loss = 0.0000\n",
      "Epoch 292/400, Participant 7: Loss = 0.0000\n",
      "Epoch 293/400, Participant 7: Loss = 0.0000\n",
      "Epoch 294/400, Participant 7: Loss = 0.0000\n",
      "Epoch 295/400, Participant 7: Loss = 0.0000\n",
      "Epoch 296/400, Participant 7: Loss = 0.0000\n",
      "Epoch 297/400, Participant 7: Loss = 0.0000\n",
      "Epoch 298/400, Participant 7: Loss = 0.0000\n",
      "Epoch 299/400, Participant 7: Loss = 0.0000\n",
      "Epoch 300/400, Participant 7: Loss = 0.0000\n",
      "Epoch 301/400, Participant 7: Loss = 0.0000\n",
      "Epoch 302/400, Participant 7: Loss = 0.0000\n",
      "Epoch 303/400, Participant 7: Loss = 0.0000\n",
      "Epoch 304/400, Participant 7: Loss = 0.0000\n",
      "Epoch 305/400, Participant 7: Loss = 0.0000\n",
      "Epoch 306/400, Participant 7: Loss = 0.0000\n",
      "Epoch 307/400, Participant 7: Loss = 0.0000\n",
      "Epoch 308/400, Participant 7: Loss = 0.0000\n",
      "Epoch 309/400, Participant 7: Loss = 0.0000\n",
      "Epoch 310/400, Participant 7: Loss = 0.0000\n",
      "Epoch 311/400, Participant 7: Loss = 0.0000\n",
      "Epoch 312/400, Participant 7: Loss = 0.0000\n",
      "Epoch 313/400, Participant 7: Loss = 0.0000\n",
      "Epoch 314/400, Participant 7: Loss = 0.0000\n",
      "Epoch 315/400, Participant 7: Loss = 0.0000\n",
      "Epoch 316/400, Participant 7: Loss = 0.0000\n",
      "Epoch 317/400, Participant 7: Loss = 0.0000\n",
      "Epoch 318/400, Participant 7: Loss = 0.0000\n",
      "Epoch 319/400, Participant 7: Loss = 0.0000\n",
      "Epoch 320/400, Participant 7: Loss = 0.0000\n",
      "Epoch 321/400, Participant 7: Loss = 0.0000\n",
      "Epoch 322/400, Participant 7: Loss = 0.0000\n",
      "Epoch 323/400, Participant 7: Loss = 0.0000\n",
      "Epoch 324/400, Participant 7: Loss = 0.0000\n",
      "Epoch 325/400, Participant 7: Loss = 0.0000\n",
      "Epoch 326/400, Participant 7: Loss = 0.0000\n",
      "Epoch 327/400, Participant 7: Loss = 0.0000\n",
      "Epoch 328/400, Participant 7: Loss = 0.0000\n",
      "Epoch 329/400, Participant 7: Loss = 0.0000\n",
      "Epoch 330/400, Participant 7: Loss = 0.0000\n",
      "Epoch 331/400, Participant 7: Loss = 0.7525\n",
      "Epoch 332/400, Participant 7: Loss = 0.6949\n",
      "Epoch 333/400, Participant 7: Loss = 0.0859\n",
      "Epoch 334/400, Participant 7: Loss = 0.0107\n",
      "Epoch 335/400, Participant 7: Loss = 0.0025\n",
      "Epoch 336/400, Participant 7: Loss = 0.0015\n",
      "Epoch 337/400, Participant 7: Loss = 0.0013\n",
      "Epoch 338/400, Participant 7: Loss = 0.0011\n",
      "Epoch 339/400, Participant 7: Loss = 0.0010\n",
      "Epoch 340/400, Participant 7: Loss = 0.0009\n",
      "Epoch 341/400, Participant 7: Loss = 0.0008\n",
      "Epoch 342/400, Participant 7: Loss = 0.0007\n",
      "Epoch 343/400, Participant 7: Loss = 0.0007\n",
      "Epoch 344/400, Participant 7: Loss = 0.0006\n",
      "Epoch 345/400, Participant 7: Loss = 0.0006\n",
      "Epoch 346/400, Participant 7: Loss = 0.0005\n",
      "Epoch 347/400, Participant 7: Loss = 0.0005\n",
      "Epoch 348/400, Participant 7: Loss = 0.0005\n",
      "Epoch 349/400, Participant 7: Loss = 0.0004\n",
      "Epoch 350/400, Participant 7: Loss = 0.0004\n",
      "Epoch 351/400, Participant 7: Loss = 0.0004\n",
      "Epoch 352/400, Participant 7: Loss = 0.0004\n",
      "Epoch 353/400, Participant 7: Loss = 0.0004\n",
      "Epoch 354/400, Participant 7: Loss = 0.0003\n",
      "Epoch 355/400, Participant 7: Loss = 0.0003\n",
      "Epoch 356/400, Participant 7: Loss = 0.0003\n",
      "Epoch 357/400, Participant 7: Loss = 0.0003\n",
      "Epoch 358/400, Participant 7: Loss = 0.0003\n",
      "Epoch 359/400, Participant 7: Loss = 0.0003\n",
      "Epoch 360/400, Participant 7: Loss = 0.0002\n",
      "Epoch 361/400, Participant 7: Loss = 0.0002\n",
      "Epoch 362/400, Participant 7: Loss = 0.0002\n",
      "Epoch 363/400, Participant 7: Loss = 0.0002\n",
      "Epoch 364/400, Participant 7: Loss = 0.0002\n",
      "Epoch 365/400, Participant 7: Loss = 0.0002\n",
      "Epoch 366/400, Participant 7: Loss = 0.0002\n",
      "Epoch 367/400, Participant 7: Loss = 0.0002\n",
      "Epoch 368/400, Participant 7: Loss = 0.0002\n",
      "Epoch 369/400, Participant 7: Loss = 0.0002\n",
      "Epoch 370/400, Participant 7: Loss = 0.0001\n",
      "Epoch 371/400, Participant 7: Loss = 0.0001\n",
      "Epoch 372/400, Participant 7: Loss = 0.0001\n",
      "Epoch 373/400, Participant 7: Loss = 0.0001\n",
      "Epoch 374/400, Participant 7: Loss = 0.0001\n",
      "Epoch 375/400, Participant 7: Loss = 0.0001\n",
      "Epoch 376/400, Participant 7: Loss = 0.0001\n",
      "Epoch 377/400, Participant 7: Loss = 0.0001\n",
      "Epoch 378/400, Participant 7: Loss = 0.0001\n",
      "Epoch 379/400, Participant 7: Loss = 0.0001\n",
      "Epoch 380/400, Participant 7: Loss = 0.0001\n",
      "Epoch 381/400, Participant 7: Loss = 0.0001\n",
      "Epoch 382/400, Participant 7: Loss = 0.0001\n",
      "Epoch 383/400, Participant 7: Loss = 0.0001\n",
      "Epoch 384/400, Participant 7: Loss = 0.0001\n",
      "Epoch 385/400, Participant 7: Loss = 0.0001\n",
      "Epoch 386/400, Participant 7: Loss = 0.0001\n",
      "Epoch 387/400, Participant 7: Loss = 0.0001\n",
      "Epoch 388/400, Participant 7: Loss = 0.0001\n",
      "Epoch 389/400, Participant 7: Loss = 0.0001\n",
      "Epoch 390/400, Participant 7: Loss = 0.0000\n",
      "Epoch 391/400, Participant 7: Loss = 0.0000\n",
      "Epoch 392/400, Participant 7: Loss = 0.0000\n",
      "Epoch 393/400, Participant 7: Loss = 0.0000\n",
      "Epoch 394/400, Participant 7: Loss = 0.0000\n",
      "Epoch 395/400, Participant 7: Loss = 0.0000\n",
      "Epoch 396/400, Participant 7: Loss = 0.0000\n",
      "Epoch 397/400, Participant 7: Loss = 0.0000\n",
      "Epoch 398/400, Participant 7: Loss = 0.0000\n",
      "Epoch 399/400, Participant 7: Loss = 0.0000\n",
      "Epoch 400/400, Participant 7: Loss = 0.0000\n",
      "LOPO Test Participant 7: Accuracy = 13.12%, F1 Score = 0.13\n",
      "Training excluding Participant 8\n",
      "Epoch 1/400, Participant 8: Loss = 3.0005\n",
      "Epoch 2/400, Participant 8: Loss = 2.6680\n",
      "Epoch 3/400, Participant 8: Loss = 2.4793\n",
      "Epoch 4/400, Participant 8: Loss = 2.3247\n",
      "Epoch 5/400, Participant 8: Loss = 2.1615\n",
      "Epoch 6/400, Participant 8: Loss = 2.0089\n",
      "Epoch 7/400, Participant 8: Loss = 1.8315\n",
      "Epoch 8/400, Participant 8: Loss = 1.6568\n",
      "Epoch 9/400, Participant 8: Loss = 1.4915\n",
      "Epoch 10/400, Participant 8: Loss = 1.3135\n",
      "Epoch 11/400, Participant 8: Loss = 1.1479\n",
      "Epoch 12/400, Participant 8: Loss = 0.9835\n",
      "Epoch 13/400, Participant 8: Loss = 0.8308\n",
      "Epoch 14/400, Participant 8: Loss = 0.6834\n",
      "Epoch 15/400, Participant 8: Loss = 0.5553\n",
      "Epoch 16/400, Participant 8: Loss = 0.4393\n",
      "Epoch 17/400, Participant 8: Loss = 0.3271\n",
      "Epoch 18/400, Participant 8: Loss = 0.2348\n",
      "Epoch 19/400, Participant 8: Loss = 0.1643\n",
      "Epoch 20/400, Participant 8: Loss = 0.1055\n",
      "Epoch 21/400, Participant 8: Loss = 0.0698\n",
      "Epoch 22/400, Participant 8: Loss = 0.0419\n",
      "Epoch 23/400, Participant 8: Loss = 0.0272\n",
      "Epoch 24/400, Participant 8: Loss = 0.0191\n",
      "Epoch 25/400, Participant 8: Loss = 0.0145\n",
      "Epoch 26/400, Participant 8: Loss = 0.0115\n",
      "Epoch 27/400, Participant 8: Loss = 0.0095\n",
      "Epoch 28/400, Participant 8: Loss = 0.0080\n",
      "Epoch 29/400, Participant 8: Loss = 0.0068\n",
      "Epoch 30/400, Participant 8: Loss = 0.0059\n",
      "Epoch 31/400, Participant 8: Loss = 0.0051\n",
      "Epoch 32/400, Participant 8: Loss = 0.0045\n",
      "Epoch 33/400, Participant 8: Loss = 0.0040\n",
      "Epoch 34/400, Participant 8: Loss = 0.0035\n",
      "Epoch 35/400, Participant 8: Loss = 0.0031\n",
      "Epoch 36/400, Participant 8: Loss = 0.0028\n",
      "Epoch 37/400, Participant 8: Loss = 0.0025\n",
      "Epoch 38/400, Participant 8: Loss = 0.0022\n",
      "Epoch 39/400, Participant 8: Loss = 0.0020\n",
      "Epoch 40/400, Participant 8: Loss = 0.0018\n",
      "Epoch 41/400, Participant 8: Loss = 0.0016\n",
      "Epoch 42/400, Participant 8: Loss = 0.0015\n",
      "Epoch 43/400, Participant 8: Loss = 0.0013\n",
      "Epoch 44/400, Participant 8: Loss = 0.0012\n",
      "Epoch 45/400, Participant 8: Loss = 0.0011\n",
      "Epoch 46/400, Participant 8: Loss = 0.0010\n",
      "Epoch 47/400, Participant 8: Loss = 0.0009\n",
      "Epoch 48/400, Participant 8: Loss = 0.0008\n",
      "Epoch 49/400, Participant 8: Loss = 0.0008\n",
      "Epoch 50/400, Participant 8: Loss = 0.0007\n",
      "Epoch 51/400, Participant 8: Loss = 0.0006\n",
      "Epoch 52/400, Participant 8: Loss = 0.0006\n",
      "Epoch 53/400, Participant 8: Loss = 0.0005\n",
      "Epoch 54/400, Participant 8: Loss = 0.0005\n",
      "Epoch 55/400, Participant 8: Loss = 0.0004\n",
      "Epoch 56/400, Participant 8: Loss = 0.0004\n",
      "Epoch 57/400, Participant 8: Loss = 0.0004\n",
      "Epoch 58/400, Participant 8: Loss = 0.0003\n",
      "Epoch 59/400, Participant 8: Loss = 0.0003\n",
      "Epoch 60/400, Participant 8: Loss = 0.0003\n",
      "Epoch 61/400, Participant 8: Loss = 0.0003\n",
      "Epoch 62/400, Participant 8: Loss = 0.0002\n",
      "Epoch 63/400, Participant 8: Loss = 0.0002\n",
      "Epoch 64/400, Participant 8: Loss = 0.0002\n",
      "Epoch 65/400, Participant 8: Loss = 0.0002\n",
      "Epoch 66/400, Participant 8: Loss = 0.0002\n",
      "Epoch 67/400, Participant 8: Loss = 0.0002\n",
      "Epoch 68/400, Participant 8: Loss = 0.0001\n",
      "Epoch 69/400, Participant 8: Loss = 0.0001\n",
      "Epoch 70/400, Participant 8: Loss = 0.0001\n",
      "Epoch 71/400, Participant 8: Loss = 0.0001\n",
      "Epoch 72/400, Participant 8: Loss = 0.0001\n",
      "Epoch 73/400, Participant 8: Loss = 0.0001\n",
      "Epoch 74/400, Participant 8: Loss = 0.0001\n",
      "Epoch 75/400, Participant 8: Loss = 0.0001\n",
      "Epoch 76/400, Participant 8: Loss = 0.0001\n"
     ]
    }
   ],
   "source": [
    "participants = set(dataset['participant'].unique())\n",
    "\n",
    "results = []\n",
    "\n",
    "for test_participant in participants:\n",
    "    print(f\"Training excluding Participant {test_participant}\")\n",
    "    train_indices = [i for i, p in enumerate(dataset['participant']) if p != test_participant]\n",
    "    test_indices = [i for i, p in enumerate(dataset['participant']) if p == test_participant]\n",
    "    train_data = dataset.select(train_indices)\n",
    "    test_data = dataset.select(test_indices)\n",
    "    model = SequenceModel().to(\"cuda\")\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=0.001)\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        train_dataloader = DataLoader(train_data, batch_size=64, shuffle=True, drop_last=True)\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for inputs in train_dataloader:\n",
    "            codes = inputs['codes'].to(torch.int64)\n",
    "            targets = inputs['label']\n",
    "            one_hot_targets = F.one_hot(targets, num_classes=24).to(torch.float)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(codes)\n",
    "            loss = loss_function(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        epoch_loss = running_loss / len(train_dataloader)\n",
    "        print(f'Epoch {epoch}/{epochs}, Participant {test_participant}: Loss = {epoch_loss:.4f}')\n",
    "    \n",
    "    test_dataloader = DataLoader(test_data, batch_size=64, shuffle=False, drop_last=True)\n",
    "    model.eval()\n",
    "    true_labels = []\n",
    "    predicted_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs in test_dataloader:\n",
    "            codes = inputs['codes'].to(torch.int64)\n",
    "            targets = inputs['label']\n",
    "            true_labels.extend(targets.cpu().numpy())\n",
    "            outputs = model(codes)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            predicted_labels.extend(predicted.cpu().numpy())\n",
    "\n",
    "    accuracy = np.mean(np.array(true_labels) == np.array(predicted_labels))\n",
    "    f1 = f1_score(true_labels, predicted_labels, average='weighted')\n",
    "\n",
    "    print(f'LOPO Test Participant {test_participant}: Accuracy = {accuracy * 100:.2f}%, F1 Score = {f1:.2f}')\n",
    "    results.append((test_participant, accuracy, f1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
