{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3a95f0a-c11e-43a4-8ac7-a50518df3d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from fastprogress.fastprogress import master_bar, progress_bar\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef45ffef-d3a0-48c5-bd8f-07916437d906",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SequenceModel, self).__init__()\n",
    "        self.num_positions = 9\n",
    "        self.num_embeddings = 1024\n",
    "        self.embedding_dim = 6\n",
    "        \n",
    "        self.embeddings = nn.ModuleList([\n",
    "            nn.Embedding(num_embeddings=self.num_embeddings, embedding_dim=self.embedding_dim) \n",
    "            for _ in range(self.num_positions)\n",
    "        ])\n",
    "        \n",
    "        self.conv1 = nn.Conv1d(in_channels=54,  out_channels=72,  kernel_size=3, stride=3)\n",
    "        self.conv2 = nn.Conv1d(in_channels=72,  out_channels=120, kernel_size=3, stride=3)\n",
    "        \n",
    "        self.fc1 = nn.Linear(120, 120)\n",
    "        self.fc2 = nn.Linear(120, 24)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        embeddings = [self.embeddings[i](x[:, :, i]) for i in range(self.num_positions)]\n",
    "        embeddings = torch.stack(embeddings, dim=3)\n",
    "        reshaped = embeddings.view(batch_size, 54, -1)\n",
    "        x = F.relu(self.conv1(reshaped))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = x.view(batch_size, -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13465be5-b360-4a0f-b2ae-e78135e8a408",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"danjacobellis/audio_har_descript_44kHz_frames\",split='train').with_format(\"torch\",device=\"cuda\")\n",
    "model = SequenceModel().to(\"cuda\")\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b083db30-c219-4c63-be84-d5433297617d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Epoch 1: Train Loss: 2.8953<p>Epoch 2: Train Loss: 2.5663<p>Epoch 3: Train Loss: 2.3701<p>Epoch 4: Train Loss: 2.1724<p>Epoch 5: Train Loss: 1.9565<p>Epoch 6: Train Loss: 1.7323<p>Epoch 7: Train Loss: 1.4968<p>Epoch 8: Train Loss: 1.2552<p>Epoch 9: Train Loss: 1.0136<p>Epoch 10: Train Loss: 0.7966<p>Epoch 11: Train Loss: 0.6042<p>Epoch 12: Train Loss: 0.4765<p>Epoch 13: Train Loss: 0.3076<p>Epoch 14: Train Loss: 0.2256<p>Epoch 15: Train Loss: 0.1976<p>Epoch 16: Train Loss: 0.1794<p>Epoch 17: Train Loss: 0.1581<p>Epoch 18: Train Loss: 0.1340<p>Epoch 19: Train Loss: 0.1178<p>Epoch 20: Train Loss: 0.1170<p>Epoch 21: Train Loss: 0.1061<p>Epoch 22: Train Loss: 0.1836<p>Epoch 23: Train Loss: 0.0775<p>Epoch 24: Train Loss: 0.0369<p>Epoch 25: Train Loss: 0.0189"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = 25\n",
    "mb = master_bar(range(1, epochs + 1))\n",
    "train_loss = []\n",
    "\n",
    "for epoch in mb:\n",
    "    dataloader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs in progress_bar(dataloader, parent=mb):\n",
    "        codes = inputs['codes'].to(torch.int64)\n",
    "        targets = inputs['label']\n",
    "        one_hot_targets = F.one_hot(targets, num_classes=24).to(torch.float)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(codes)\n",
    "        loss = loss_function(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    epoch_loss = running_loss / len(dataloader)\n",
    "    train_loss.append(epoch_loss)\n",
    "\n",
    "    mb.write(f'Epoch {epoch}: Train Loss: {epoch_loss:.4f}')\n",
    "    \n",
    "    graphs = [[range(1, epoch + 1), train_loss]]\n",
    "    x_bounds = [1, epochs]\n",
    "    y_bounds = [min(train_loss) - 0.05, max(train_loss) + 0.05]\n",
    "    mb.update_graph(graphs, x_bounds, y_bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6654f6c8-2e7f-4e52-9c6f-441107573032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the training set: 99.61%\n",
      "F1 Score on the training set: 1.00\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "true_labels = []\n",
    "predicted_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs in dataloader:\n",
    "        codes = inputs['codes'].to(torch.int64)\n",
    "        targets = inputs['label']\n",
    "        true_labels.extend(targets.cpu().numpy())\n",
    "        outputs = model(codes)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        predicted_labels.extend(predicted.cpu().numpy())\n",
    "\n",
    "accuracy = np.mean(np.array(true_labels) == np.array(predicted_labels))\n",
    "print(f'Accuracy on the training set: {accuracy * 100:.2f}%')\n",
    "\n",
    "f1 = f1_score(true_labels, predicted_labels, average='weighted')\n",
    "print(f'F1 Score on the training set: {f1:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f2005efc-fd24-4d02-aa14-a2664754251a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training excluding Participant 1\n",
      "Epoch 1/25, Participant 1: Loss = 2.8885\n",
      "Epoch 2/25, Participant 1: Loss = 2.5471\n",
      "Epoch 3/25, Participant 1: Loss = 2.3476\n",
      "Epoch 4/25, Participant 1: Loss = 2.1537\n",
      "Epoch 5/25, Participant 1: Loss = 1.9420\n",
      "Epoch 6/25, Participant 1: Loss = 1.7092\n",
      "Epoch 7/25, Participant 1: Loss = 1.4643\n",
      "Epoch 8/25, Participant 1: Loss = 1.2217\n",
      "Epoch 9/25, Participant 1: Loss = 0.9959\n",
      "Epoch 10/25, Participant 1: Loss = 0.7879\n",
      "Epoch 11/25, Participant 1: Loss = 0.5990\n",
      "Epoch 12/25, Participant 1: Loss = 0.4299\n",
      "Epoch 13/25, Participant 1: Loss = 0.3332\n",
      "Epoch 14/25, Participant 1: Loss = 0.2583\n",
      "Epoch 15/25, Participant 1: Loss = 0.1832\n",
      "Epoch 16/25, Participant 1: Loss = 0.1636\n",
      "Epoch 17/25, Participant 1: Loss = 0.1432\n",
      "Epoch 18/25, Participant 1: Loss = 0.1118\n",
      "Epoch 19/25, Participant 1: Loss = 0.1404\n",
      "Epoch 20/25, Participant 1: Loss = 0.1125\n",
      "Epoch 21/25, Participant 1: Loss = 0.0870\n",
      "Epoch 22/25, Participant 1: Loss = 0.0715\n",
      "Epoch 23/25, Participant 1: Loss = 0.0978\n",
      "Epoch 24/25, Participant 1: Loss = 0.1364\n",
      "Epoch 25/25, Participant 1: Loss = 0.0629\n",
      "LOPO Test Participant 1: Accuracy = 14.22%, F1 Score = 0.15\n",
      "Training excluding Participant 5\n",
      "Epoch 1/25, Participant 5: Loss = 2.8667\n",
      "Epoch 2/25, Participant 5: Loss = 2.5474\n",
      "Epoch 3/25, Participant 5: Loss = 2.3588\n",
      "Epoch 4/25, Participant 5: Loss = 2.1750\n",
      "Epoch 5/25, Participant 5: Loss = 1.9645\n",
      "Epoch 6/25, Participant 5: Loss = 1.7405\n",
      "Epoch 7/25, Participant 5: Loss = 1.5003\n",
      "Epoch 8/25, Participant 5: Loss = 1.2550\n",
      "Epoch 9/25, Participant 5: Loss = 1.0255\n",
      "Epoch 10/25, Participant 5: Loss = 0.8030\n",
      "Epoch 11/25, Participant 5: Loss = 0.6083\n",
      "Epoch 12/25, Participant 5: Loss = 0.4456\n",
      "Epoch 13/25, Participant 5: Loss = 0.3218\n",
      "Epoch 14/25, Participant 5: Loss = 0.2487\n",
      "Epoch 15/25, Participant 5: Loss = 0.1921\n",
      "Epoch 16/25, Participant 5: Loss = 0.1368\n",
      "Epoch 17/25, Participant 5: Loss = 0.1369\n",
      "Epoch 18/25, Participant 5: Loss = 0.1587\n",
      "Epoch 19/25, Participant 5: Loss = 0.1347\n",
      "Epoch 20/25, Participant 5: Loss = 0.0946\n",
      "Epoch 21/25, Participant 5: Loss = 0.0926\n",
      "Epoch 22/25, Participant 5: Loss = 0.1163\n",
      "Epoch 23/25, Participant 5: Loss = 0.1021\n",
      "Epoch 24/25, Participant 5: Loss = 0.0758\n",
      "Epoch 25/25, Participant 5: Loss = 0.0616\n",
      "LOPO Test Participant 5: Accuracy = 14.43%, F1 Score = 0.14\n",
      "Training excluding Participant 2\n",
      "Epoch 1/25, Participant 2: Loss = 2.8726\n",
      "Epoch 2/25, Participant 2: Loss = 2.5534\n",
      "Epoch 3/25, Participant 2: Loss = 2.3590\n",
      "Epoch 4/25, Participant 2: Loss = 2.1510\n",
      "Epoch 5/25, Participant 2: Loss = 1.9324\n",
      "Epoch 6/25, Participant 2: Loss = 1.7001\n",
      "Epoch 7/25, Participant 2: Loss = 1.4616\n",
      "Epoch 8/25, Participant 2: Loss = 1.2184\n",
      "Epoch 9/25, Participant 2: Loss = 0.9995\n",
      "Epoch 10/25, Participant 2: Loss = 0.7787\n",
      "Epoch 11/25, Participant 2: Loss = 0.5932\n",
      "Epoch 12/25, Participant 2: Loss = 0.4294\n",
      "Epoch 13/25, Participant 2: Loss = 0.3202\n",
      "Epoch 14/25, Participant 2: Loss = 0.2375\n",
      "Epoch 15/25, Participant 2: Loss = 0.1921\n",
      "Epoch 16/25, Participant 2: Loss = 0.1316\n",
      "Epoch 17/25, Participant 2: Loss = 0.1583\n",
      "Epoch 18/25, Participant 2: Loss = 0.1547\n",
      "Epoch 19/25, Participant 2: Loss = 0.1137\n",
      "Epoch 20/25, Participant 2: Loss = 0.0695\n",
      "Epoch 21/25, Participant 2: Loss = 0.0559\n",
      "Epoch 22/25, Participant 2: Loss = 0.1454\n",
      "Epoch 23/25, Participant 2: Loss = 0.1479\n",
      "Epoch 24/25, Participant 2: Loss = 0.0910\n",
      "Epoch 25/25, Participant 2: Loss = 0.0517\n",
      "LOPO Test Participant 2: Accuracy = 13.12%, F1 Score = 0.13\n",
      "Training excluding Participant 7\n",
      "Epoch 1/25, Participant 7: Loss = 2.8963\n",
      "Epoch 2/25, Participant 7: Loss = 2.5503\n",
      "Epoch 3/25, Participant 7: Loss = 2.3353\n",
      "Epoch 4/25, Participant 7: Loss = 2.1314\n",
      "Epoch 5/25, Participant 7: Loss = 1.9136\n",
      "Epoch 6/25, Participant 7: Loss = 1.6723\n",
      "Epoch 7/25, Participant 7: Loss = 1.4222\n",
      "Epoch 8/25, Participant 7: Loss = 1.1866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _xla_gc_callback at 0x72e6200adfc0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/server/.local/lib/python3.10/site-packages/jax/_src/lib/__init__.py\", line 103, in _xla_gc_callback\n",
      "    def _xla_gc_callback(*args):\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 32\u001b[0m\n\u001b[1;32m     29\u001b[0m one_hot_targets \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mone_hot(targets, num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m24\u001b[39m)\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat)\n\u001b[1;32m     31\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 32\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcodes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_function(outputs, targets)\n\u001b[1;32m     34\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[2], line 25\u001b[0m, in \u001b[0;36mSequenceModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     23\u001b[0m reshaped \u001b[38;5;241m=\u001b[39m embeddings\u001b[38;5;241m.\u001b[39mview(batch_size, \u001b[38;5;241m54\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     24\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1(reshaped))\n\u001b[0;32m---> 25\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     26\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mview(batch_size, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     27\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc1(x))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py:310\u001b[0m, in \u001b[0;36mConv1d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py:306\u001b[0m, in \u001b[0;36mConv1d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv1d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    304\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    305\u001b[0m                     _single(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 306\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "\n",
    "participants = set(dataset['participant'].unique())  # Assume dataset['participant'] gives participant IDs\n",
    "\n",
    "results = []\n",
    "\n",
    "for test_participant in participants:\n",
    "    print(f\"Training excluding Participant {test_participant}\")\n",
    "    \n",
    "    # Indices for training and test set based on excluding the current test_participant\n",
    "    train_indices = [i for i, p in enumerate(dataset['participant']) if p != test_participant]\n",
    "    test_indices = [i for i, p in enumerate(dataset['participant']) if p == test_participant]\n",
    "    \n",
    "    # Select data for the current fold\n",
    "    train_data = dataset.select(train_indices)\n",
    "    test_data = dataset.select(test_indices)\n",
    "    \n",
    "    # Initialize the model, optimizer, and dataloaders for each fold\n",
    "    model = SequenceModel().to(\"cuda\")\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=0.001)\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        # Recreate dataloaders inside the epoch loop if you wish the order of samples to be shuffled in each epoch\n",
    "        train_dataloader = DataLoader(train_data, batch_size=16, shuffle=True, drop_last=True)\n",
    "        \n",
    "        model.train()  # Ensure model is in training mode\n",
    "        running_loss = 0.0\n",
    "        for inputs in train_dataloader:\n",
    "            codes = inputs['codes'].to(torch.int64)\n",
    "            targets = inputs['label']\n",
    "            one_hot_targets = F.one_hot(targets, num_classes=24).to(torch.float)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(codes)\n",
    "            loss = loss_function(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        # Calculate training loss for the epoch\n",
    "        epoch_loss = running_loss / len(train_dataloader)\n",
    "        print(f'Epoch {epoch}/{epochs}, Participant {test_participant}: Loss = {epoch_loss:.4f}')\n",
    "    \n",
    "    # Evaluation for the fold\n",
    "    test_dataloader = DataLoader(test_data, batch_size=16, shuffle=False, drop_last=True)\n",
    "    model.eval()\n",
    "    true_labels = []\n",
    "    predicted_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs in test_dataloader:\n",
    "            codes = inputs['codes'].to(torch.int64)\n",
    "            targets = inputs['label']\n",
    "            true_labels.extend(targets.cpu().numpy())\n",
    "            outputs = model(codes)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            predicted_labels.extend(predicted.cpu().numpy())\n",
    "\n",
    "    accuracy = np.mean(np.array(true_labels) == np.array(predicted_labels))\n",
    "    f1 = f1_score(true_labels, predicted_labels, average='weighted')\n",
    "\n",
    "    print(f'LOPO Test Participant {test_participant}: Accuracy = {accuracy * 100:.2f}%, F1 Score = {f1:.2f}')\n",
    "    results.append((test_participant, accuracy, f1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
