{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75ab9b8d-ec3c-4f44-8e87-aa4bd7a55b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dgj335/.local/lib/python3.10/site-packages/beartype/_util/error/utilerrwarn.py:67: BeartypeModuleUnimportableWarning: Ignoring module \"onnx\" importation exception:\n",
      "    ImportError: cannot import name 'builder' from 'google.protobuf.internal' (/home/dgj335/.local/lib/python3.10/site-packages/google/protobuf/internal/__init__.py)\n",
      "  warn(message, cls)\n",
      "/home/dgj335/.local/lib/python3.10/site-packages/beartype/_util/error/utilerrwarn.py:67: BeartypeModuleUnimportableWarning: Ignoring module \"onnx\" importation exception:\n",
      "    ImportError: cannot import name 'builder' from 'google.protobuf.internal' (/home/dgj335/.local/lib/python3.10/site-packages/google/protobuf/internal/__init__.py)\n",
      "  warn(message, cls)\n",
      "/home/dgj335/.local/lib/python3.10/site-packages/beartype/_util/error/utilerrwarn.py:67: BeartypeModuleUnimportableWarning: Ignoring module \"onnx\" importation exception:\n",
      "    ImportError: cannot import name 'builder' from 'google.protobuf.internal' (/home/dgj335/.local/lib/python3.10/site-packages/google/protobuf/internal/__init__.py)\n",
      "  warn(message, cls)\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch\n",
    "from x_transformers import ViTransformerWrapper, Encoder\n",
    "from fastprogress.fastprogress import master_bar, progress_bar\n",
    "from torchvision.transforms import RandomResizedCrop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70b31d2e-9bc5-4c5c-b780-3f0a94a3a669",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = load_dataset(\"frgfm/imagenette\",\"full_size\",split=\"train\")\n",
    "rgb_train = train_dataset.filter(lambda s: s[\"image\"].mode == \"RGB\").with_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53695141-a7c7-4512-91c2-a34eb006d80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ViTransformerWrapper(\n",
    "    image_size = 256,\n",
    "    patch_size = 32,\n",
    "    num_classes = 10,\n",
    "    attn_layers = Encoder(\n",
    "        dim = 512,\n",
    "        depth = 6,\n",
    "        heads = 8,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f8ed3c7-2df0-4717-8d75-55f50f221033",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = 5\n",
    "mb = master_bar(range(1, epochs + 1))\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "val_accuracy = []\n",
    "batch_size = 32\n",
    "rr_crop = RandomResizedCrop(256,antialias=True);\n",
    "for epoch in mb:\n",
    "    dataloader_train = iter(DataLoader(rgb_train, batch_size=1, shuffle=True, drop_last=True))\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i_batch in progress_bar(range(train_dataset.num_rows//batch_size), parent=mb):\n",
    "        x = torch.zeros(batch_size, 3, 256, 256, dtype=torch.float32)\n",
    "        targets = torch.zeros(batch_size,dtype=torch.int64)\n",
    "        for i_sample in range(batch_size):\n",
    "            inputs = next(dataloader_train)\n",
    "            x[i_sample,:,:,:] = rr_crop(inputs['image'].permute((0,3,1,2)))\n",
    "            targets[i_sample] = inputs['label']\n",
    "        break\n",
    "        # x = x.cuda()\n",
    "        # targets = inputs['label'].to(torch.int64).cuda()\n",
    "    #     optimizer.zero_grad()\n",
    "    #     outputs = model(x)\n",
    "    #     loss = loss_function(outputs, targets)\n",
    "    #     if torch.isnan(loss):\n",
    "    #         print(f\"Loss is nan, skipping batch\")\n",
    "    #         continue\n",
    "    #     loss.backward()\n",
    "    #     print(loss.item(), end='\\r')\n",
    "    #     # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "    #     optimizer.step()\n",
    "    #     running_loss += loss.item()\n",
    "\n",
    "    # train_epoch_loss = running_loss / len(dataloader_train)\n",
    "    # train_loss.append(train_epoch_loss)\n",
    "    \n",
    "    # # Validation Phase\n",
    "    # dataloader_val = DataLoader(dataset['validation'], batch_size=256, shuffle=False, drop_last=False)\n",
    "    # model.eval()\n",
    "    # running_loss_val = 0.0\n",
    "    # correct_predictions = 0\n",
    "    # total_predictions = 0\n",
    "    # with torch.no_grad():\n",
    "    #     for inputs in dataloader_val:\n",
    "    #         x = center_crop(inputs['latent'].cuda())\n",
    "    #         targets = inputs['label'].to(torch.int64).cuda()\n",
    "    #         outputs = model(x)\n",
    "    #         loss = loss_function(outputs, targets)\n",
    "    #         if torch.isnan(loss):\n",
    "    #             print(f\"Loss is nan, skipping batch\")\n",
    "    #             continue\n",
    "    #         running_loss_val += loss.item()\n",
    "    #         _, predicted = torch.max(outputs, 1)\n",
    "    #         correct_predictions += (predicted == targets).sum().item()\n",
    "    #         total_predictions += targets.size(0)\n",
    "    # val_epoch_loss = running_loss_val / len(dataloader_val)\n",
    "    # test_loss.append(val_epoch_loss)\n",
    "    # epoch_accuracy = correct_predictions / total_predictions\n",
    "    # print(f'Epoch: {epoch}, Accuracy: {epoch_accuracy:.4f}')\n",
    "    # val_accuracy.append(epoch_accuracy)\n",
    "    # graphs = [\n",
    "    #     [range(1, epoch + 1), train_loss],  # Training Loss\n",
    "    #     [range(1, epoch + 1), test_loss],  # Validation Loss\n",
    "    # ]\n",
    "    # x_bounds = [1, epoch]\n",
    "    # y_bounds = [min(min(train_loss + test_loss) - 0.05, 0), max(max(train_loss + test_loss) + 0.05, 1)]\n",
    "    # mb.update_graph(graphs, x_bounds, y_bounds)\n",
    "    # checkpoint_filename = f'checkpoint{epoch}.pt'\n",
    "    # torch.save(model.state_dict(), checkpoint_filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
