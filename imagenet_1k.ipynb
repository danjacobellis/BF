{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75ab9b8d-ec3c-4f44-8e87-aa4bd7a55b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/server/danjacobellis/BF/convnext.py:159: UserWarning: Overwriting convnext_tiny in registry with convnext.convnext_tiny. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  def convnext_tiny(pretrained=False,in_22k=False, **kwargs):\n",
      "/home/server/danjacobellis/BF/convnext.py:168: UserWarning: Overwriting convnext_small in registry with convnext.convnext_small. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  def convnext_small(pretrained=False,in_22k=False, **kwargs):\n",
      "/home/server/danjacobellis/BF/convnext.py:177: UserWarning: Overwriting convnext_base in registry with convnext.convnext_base. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  def convnext_base(pretrained=False, in_22k=False, **kwargs):\n",
      "/home/server/danjacobellis/BF/convnext.py:186: UserWarning: Overwriting convnext_large in registry with convnext.convnext_large. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  def convnext_large(pretrained=False, in_22k=False, **kwargs):\n",
      "/home/server/danjacobellis/BF/convnext.py:195: UserWarning: Overwriting convnext_xlarge in registry with convnext.convnext_xlarge. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  def convnext_xlarge(pretrained=False, in_22k=False, **kwargs):\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from convnext import ConvNeXt\n",
    "from fastprogress.fastprogress import master_bar, progress_bar\n",
    "from torchvision.transforms import RandomResizedCrop, CenterCrop, Resize, RandomHorizontalFlip, Compose\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70b31d2e-9bc5-4c5c-b780-3f0a94a3a669",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dd306d8c985420989df1a51086f71a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/257 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset = load_dataset(\"imagenet-1k\",split=\"train\",trust_remote_code=True)\n",
    "valid_dataset = load_dataset(\"imagenet-1k\",split=\"validation\",trust_remote_code=True)\n",
    "rgb_train = train_dataset.filter(lambda s: s[\"image\"].mode == \"RGB\").with_format(\"torch\")\n",
    "rgb_valid = valid_dataset.filter(lambda s: s[\"image\"].mode == \"RGB\").with_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "580d7dab-058a-473c-8c87-f0370425e4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_fn(batch):\n",
    "    train_transforms = Compose(\n",
    "        [\n",
    "            RandomResizedCrop(256, scale=(0.5,1.0), ratio=(0.8, 1.25)),\n",
    "            RandomHorizontalFlip(),\n",
    "        ]\n",
    "    )\n",
    "    images = torch.stack([train_transforms(item['image'].permute(2,0,1).to(torch.float)/255) for item in batch])\n",
    "    labels = torch.tensor([item['label'] for item in batch], dtype=torch.int64)\n",
    "    return images, labels\n",
    "\n",
    "val_transforms = Compose(\n",
    "    [\n",
    "        Resize(256,antialias=True),\n",
    "        CenterCrop(256),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "321dad4c-7bbd-4ef3-b9e7-2f648b74f4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = ConvNeXt(in_chans=3,\n",
    "                      num_classes=1000,\n",
    "                      depths=[3, 3, 9, 3],\n",
    "                      dims=[96, 192, 384, 768],\n",
    "                      drop_path_rate=0.,\n",
    "                      layer_scale_init_value=1e-6,\n",
    "                      head_init_scale=1.).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53695141-a7c7-4512-91c2-a34eb006d80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "batch_size = 128\n",
    "accumulation_steps = 1024//batch_size\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "optimizer = AdamW(classifier.parameters(), lr=0.001, weight_decay=1e-3)\n",
    "scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2, eta_min=1e-6)\n",
    "\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "val_accuracy = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8ed3c7-2df0-4717-8d75-55f50f221033",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='0' class='' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/50 00:00&lt;?]\n",
       "    </div>\n",
       "    \n",
       "\n",
       "\n",
       "    <div>\n",
       "      <progress value='2170' class='' max='9853' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      22.02% [2170/9853 21:06&lt;1:14:45]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.5663051605224615\r"
     ]
    }
   ],
   "source": [
    "mb = master_bar(range(1, epochs + 1))\n",
    "\n",
    "for epoch in mb:\n",
    "    \n",
    "    dataloader_train = DataLoader(rgb_train, batch_size=batch_size, shuffle=True, drop_last=True, num_workers=12, collate_fn=custom_collate_fn)\n",
    "    dataloader_valid = DataLoader(rgb_valid, batch_size=1, shuffle=False, drop_last=False)\n",
    "\n",
    "    # Training\n",
    "    classifier.train()\n",
    "    optimizer.zero_grad()\n",
    "    running_loss = 0.0\n",
    "    for i_batch, (x, target) in enumerate(progress_bar(dataloader_train, parent=mb)):\n",
    "        x = x.cuda()\n",
    "        outputs = classifier(x)\n",
    "        loss = loss_function(outputs, target.cuda())\n",
    "        loss.backward()\n",
    "        print(loss.item(), end='\\r')\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        if (i_batch + 1) % accumulation_steps == 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "    train_epoch_loss = running_loss / len(dataloader_train)\n",
    "    train_loss.append(train_epoch_loss)\n",
    "    \n",
    "    # Validation\n",
    "    classifier.eval()\n",
    "    running_loss_val = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs in dataloader_valid:\n",
    "            x = inputs['image'].permute(0,3,1,2).to(torch.float)/255\n",
    "            x = val_transforms(x).cuda()\n",
    "            targets = inputs['label'].to(torch.int64).cuda()\n",
    "            outputs = classifier(x)\n",
    "            loss = loss_function(outputs, targets)\n",
    "            running_loss_val += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct_predictions += (predicted == targets).sum().item()\n",
    "            total_predictions += targets.size(0)\n",
    "    val_epoch_loss = running_loss_val / len(dataloader_valid)\n",
    "    test_loss.append(val_epoch_loss)\n",
    "    epoch_accuracy = correct_predictions / total_predictions\n",
    "    print(f'Epoch: {epoch}, Accuracy: {epoch_accuracy:.4f}')\n",
    "    val_accuracy.append(epoch_accuracy)\n",
    "    graphs = [\n",
    "        [range(1, epoch + 1), train_loss],  # Training Loss\n",
    "        [range(1, epoch + 1), test_loss],  # Validation Loss\n",
    "    ]\n",
    "    x_bounds = [1, epoch]\n",
    "    y_bounds = [min(min(train_loss + test_loss) - 0.05, 0), max(max(train_loss + test_loss) + 0.05, 1)]\n",
    "    mb.update_graph(graphs, x_bounds, y_bounds)\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b67bd5-4f58-47d4-adb2-d89cddc2461d",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_filename = f'convnext_imagenet1k_e{epoch-1}.pt'\n",
    "checkpoint = {\n",
    "    'model_state_dict': classifier.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'scheduler_state_dict': scheduler.state_dict(),\n",
    "    'epoch': epoch,\n",
    "    'train_loss': train_loss,\n",
    "    'test_loss': test_loss,\n",
    "    'val_accuracy': val_accuracy\n",
    "}\n",
    "torch.save(checkpoint, checkpoint_filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
